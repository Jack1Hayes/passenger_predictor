{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMElUhBoabfxZmLUyXEmhEf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jack1Hayes/passenger_predictor/blob/main/NN%20models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiP5I7IRHi34"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "EozN8McAHi36",
        "outputId": "63eea97b-3623-4189-8344-fe26f5fadfe1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   num_passengers sales_channel  trip_type  purchase_lead  length_of_stay  \\\n",
              "0               2      Internet  RoundTrip            262              19   \n",
              "1               1      Internet  RoundTrip            112              20   \n",
              "2               2      Internet  RoundTrip            243              22   \n",
              "3               1      Internet  RoundTrip             96              31   \n",
              "4               2      Internet  RoundTrip             68              22   \n",
              "\n",
              "   flight_hour flight_day   route booking_origin  wants_extra_baggage  \\\n",
              "0            7        Sat  AKLDEL    New Zealand                    1   \n",
              "1            3        Sat  AKLDEL    New Zealand                    0   \n",
              "2           17        Wed  AKLDEL          India                    1   \n",
              "3            4        Sat  AKLDEL    New Zealand                    0   \n",
              "4           15        Wed  AKLDEL          India                    1   \n",
              "\n",
              "   wants_preferred_seat  wants_in_flight_meals  flight_duration  \\\n",
              "0                     0                      0             5.52   \n",
              "1                     0                      0             5.52   \n",
              "2                     1                      0             5.52   \n",
              "3                     0                      1             5.52   \n",
              "4                     0                      1             5.52   \n",
              "\n",
              "   booking_complete  \n",
              "0                 0  \n",
              "1                 0  \n",
              "2                 0  \n",
              "3                 0  \n",
              "4                 0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ddaf2d8f-63cd-4834-8004-bd3b911651cd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_passengers</th>\n",
              "      <th>sales_channel</th>\n",
              "      <th>trip_type</th>\n",
              "      <th>purchase_lead</th>\n",
              "      <th>length_of_stay</th>\n",
              "      <th>flight_hour</th>\n",
              "      <th>flight_day</th>\n",
              "      <th>route</th>\n",
              "      <th>booking_origin</th>\n",
              "      <th>wants_extra_baggage</th>\n",
              "      <th>wants_preferred_seat</th>\n",
              "      <th>wants_in_flight_meals</th>\n",
              "      <th>flight_duration</th>\n",
              "      <th>booking_complete</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>Internet</td>\n",
              "      <td>RoundTrip</td>\n",
              "      <td>262</td>\n",
              "      <td>19</td>\n",
              "      <td>7</td>\n",
              "      <td>Sat</td>\n",
              "      <td>AKLDEL</td>\n",
              "      <td>New Zealand</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.52</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Internet</td>\n",
              "      <td>RoundTrip</td>\n",
              "      <td>112</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>Sat</td>\n",
              "      <td>AKLDEL</td>\n",
              "      <td>New Zealand</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.52</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Internet</td>\n",
              "      <td>RoundTrip</td>\n",
              "      <td>243</td>\n",
              "      <td>22</td>\n",
              "      <td>17</td>\n",
              "      <td>Wed</td>\n",
              "      <td>AKLDEL</td>\n",
              "      <td>India</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5.52</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Internet</td>\n",
              "      <td>RoundTrip</td>\n",
              "      <td>96</td>\n",
              "      <td>31</td>\n",
              "      <td>4</td>\n",
              "      <td>Sat</td>\n",
              "      <td>AKLDEL</td>\n",
              "      <td>New Zealand</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5.52</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>Internet</td>\n",
              "      <td>RoundTrip</td>\n",
              "      <td>68</td>\n",
              "      <td>22</td>\n",
              "      <td>15</td>\n",
              "      <td>Wed</td>\n",
              "      <td>AKLDEL</td>\n",
              "      <td>India</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5.52</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddaf2d8f-63cd-4834-8004-bd3b911651cd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ddaf2d8f-63cd-4834-8004-bd3b911651cd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ddaf2d8f-63cd-4834-8004-bd3b911651cd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/customer_booking.csv\", encoding=\"ISO-8859-1\")\n",
        "df = df = df[df.length_of_stay < 50]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NRk5cKnHi4D"
      },
      "outputs": [],
      "source": [
        "mapping = {\n",
        "    \"Mon\": 1,\n",
        "    \"Tue\": 2,\n",
        "    \"Wed\": 3,\n",
        "    \"Thu\": 4,\n",
        "    \"Fri\": 5,\n",
        "    \"Sat\": 6,\n",
        "    \"Sun\": 7,\n",
        "}\n",
        "\n",
        "#df[\"flight_day\"] = df[\"flight_day\"].map(mapping)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = {\n",
        "    \"Internet\":1,\n",
        "    \"Mobile\":0,\n",
        "    }\n",
        "\n",
        "df[\"sales_channel\"] = df[\"sales_channel\"].map(mapping)"
      ],
      "metadata": {
        "id": "pX2fALrSKEFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = {\n",
        "    \"RoundTrip\":0,\n",
        "    \"CircleTrip\":1,\n",
        "    \"OneWay\":2,\n",
        "    }\n",
        "\n",
        "df['trip_type'] = df['trip_type'].map(mapping)"
      ],
      "metadata": {
        "id": "4iHy55lZK6wU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WU0LwOB7Hi4E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "ebbe11fd-56f4-44c1-e5f9-065ef8b9cb3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   num_passengers  sales_channel  trip_type  purchase_lead  length_of_stay  \\\n",
              "0               2              1          0            262              19   \n",
              "1               1              1          0            112              20   \n",
              "2               2              1          0            243              22   \n",
              "3               1              1          0             96              31   \n",
              "4               2              1          0             68              22   \n",
              "\n",
              "   flight_hour flight_day   route booking_origin  wants_extra_baggage  \\\n",
              "0            7        Sat  AKLDEL    New Zealand                    1   \n",
              "1            3        Sat  AKLDEL    New Zealand                    0   \n",
              "2           17        Wed  AKLDEL          India                    1   \n",
              "3            4        Sat  AKLDEL    New Zealand                    0   \n",
              "4           15        Wed  AKLDEL          India                    1   \n",
              "\n",
              "   wants_preferred_seat  wants_in_flight_meals  flight_duration  \\\n",
              "0                     0                      0             5.52   \n",
              "1                     0                      0             5.52   \n",
              "2                     1                      0             5.52   \n",
              "3                     0                      1             5.52   \n",
              "4                     0                      1             5.52   \n",
              "\n",
              "   booking_complete  \n",
              "0                 0  \n",
              "1                 0  \n",
              "2                 0  \n",
              "3                 0  \n",
              "4                 0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59e70911-f65f-4d0e-b351-9f0811cfc3b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_passengers</th>\n",
              "      <th>sales_channel</th>\n",
              "      <th>trip_type</th>\n",
              "      <th>purchase_lead</th>\n",
              "      <th>length_of_stay</th>\n",
              "      <th>flight_hour</th>\n",
              "      <th>flight_day</th>\n",
              "      <th>route</th>\n",
              "      <th>booking_origin</th>\n",
              "      <th>wants_extra_baggage</th>\n",
              "      <th>wants_preferred_seat</th>\n",
              "      <th>wants_in_flight_meals</th>\n",
              "      <th>flight_duration</th>\n",
              "      <th>booking_complete</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>262</td>\n",
              "      <td>19</td>\n",
              "      <td>7</td>\n",
              "      <td>Sat</td>\n",
              "      <td>AKLDEL</td>\n",
              "      <td>New Zealand</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.52</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>112</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>Sat</td>\n",
              "      <td>AKLDEL</td>\n",
              "      <td>New Zealand</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.52</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>243</td>\n",
              "      <td>22</td>\n",
              "      <td>17</td>\n",
              "      <td>Wed</td>\n",
              "      <td>AKLDEL</td>\n",
              "      <td>India</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5.52</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96</td>\n",
              "      <td>31</td>\n",
              "      <td>4</td>\n",
              "      <td>Sat</td>\n",
              "      <td>AKLDEL</td>\n",
              "      <td>New Zealand</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5.52</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>68</td>\n",
              "      <td>22</td>\n",
              "      <td>15</td>\n",
              "      <td>Wed</td>\n",
              "      <td>AKLDEL</td>\n",
              "      <td>India</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5.52</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59e70911-f65f-4d0e-b351-9f0811cfc3b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-59e70911-f65f-4d0e-b351-9f0811cfc3b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-59e70911-f65f-4d0e-b351-9f0811cfc3b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ],
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "labelencoder = LabelEncoder()\n",
        "onehotencoder = OneHotEncoder()\n",
        "df[\"sales_channel\"]= labelencoder.fit_transform(df[\"sales_channel\"])\n",
        "\n",
        "\n",
        "df = (pd.DataFrame(df))\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(df,prefix=['route'], columns = ['route'])\n",
        "df = pd.get_dummies(df,prefix=['booking_origin'], columns = ['booking_origin'])\n",
        "df = pd.get_dummies(df,prefix=['flight_day'], columns = ['flight_day'])\n",
        "normalized_df=(df-df.min())/(df.max()-df.min())\n",
        "\n",
        "df['purchase_lead'] = (df['purchase_lead'])/867.000000\n",
        "df['length_of_stay'] = (df['length_of_stay'])/50\n",
        "df['flight_hour'] = (df['flight_hour'])/23.00000\n",
        "df['flight_durtion'] = (df['flight_duration'])/9.500000\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "Q-VHt2OFBwZ_",
        "outputId": "404538df-9430-4935-f341-35d68cbf5936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   num_passengers  sales_channel  trip_type  purchase_lead  length_of_stay  \\\n",
              "0               2              1          0       0.302191            0.38   \n",
              "1               1              1          0       0.129181            0.40   \n",
              "2               2              1          0       0.280277            0.44   \n",
              "3               1              1          0       0.110727            0.62   \n",
              "4               2              1          0       0.078431            0.44   \n",
              "\n",
              "   flight_hour  wants_extra_baggage  wants_preferred_seat  \\\n",
              "0     0.304348                    1                     0   \n",
              "1     0.130435                    0                     0   \n",
              "2     0.739130                    1                     1   \n",
              "3     0.173913                    0                     0   \n",
              "4     0.652174                    1                     0   \n",
              "\n",
              "   wants_in_flight_meals  flight_duration  ...  booking_origin_Vanuatu  \\\n",
              "0                      0             5.52  ...                       0   \n",
              "1                      0             5.52  ...                       0   \n",
              "2                      0             5.52  ...                       0   \n",
              "3                      1             5.52  ...                       0   \n",
              "4                      1             5.52  ...                       0   \n",
              "\n",
              "   booking_origin_Vietnam  flight_day_Fri  flight_day_Mon  flight_day_Sat  \\\n",
              "0                       0               0               0               1   \n",
              "1                       0               0               0               1   \n",
              "2                       0               0               0               0   \n",
              "3                       0               0               0               1   \n",
              "4                       0               0               0               0   \n",
              "\n",
              "   flight_day_Sun  flight_day_Thu  flight_day_Tue  flight_day_Wed  \\\n",
              "0               0               0               0               0   \n",
              "1               0               0               0               0   \n",
              "2               0               0               0               1   \n",
              "3               0               0               0               0   \n",
              "4               0               0               0               1   \n",
              "\n",
              "   flight_durtion  \n",
              "0        0.581053  \n",
              "1        0.581053  \n",
              "2        0.581053  \n",
              "3        0.581053  \n",
              "4        0.581053  \n",
              "\n",
              "[5 rows x 915 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df4659ea-5708-46a0-a109-2e19eb32c9fb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_passengers</th>\n",
              "      <th>sales_channel</th>\n",
              "      <th>trip_type</th>\n",
              "      <th>purchase_lead</th>\n",
              "      <th>length_of_stay</th>\n",
              "      <th>flight_hour</th>\n",
              "      <th>wants_extra_baggage</th>\n",
              "      <th>wants_preferred_seat</th>\n",
              "      <th>wants_in_flight_meals</th>\n",
              "      <th>flight_duration</th>\n",
              "      <th>...</th>\n",
              "      <th>booking_origin_Vanuatu</th>\n",
              "      <th>booking_origin_Vietnam</th>\n",
              "      <th>flight_day_Fri</th>\n",
              "      <th>flight_day_Mon</th>\n",
              "      <th>flight_day_Sat</th>\n",
              "      <th>flight_day_Sun</th>\n",
              "      <th>flight_day_Thu</th>\n",
              "      <th>flight_day_Tue</th>\n",
              "      <th>flight_day_Wed</th>\n",
              "      <th>flight_durtion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.302191</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.52</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.581053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.129181</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.130435</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.52</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.581053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.280277</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.739130</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5.52</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.581053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.110727</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5.52</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.581053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.078431</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.652174</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5.52</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.581053</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 915 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df4659ea-5708-46a0-a109-2e19eb32c9fb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-df4659ea-5708-46a0-a109-2e19eb32c9fb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-df4659ea-5708-46a0-a109-2e19eb32c9fb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from sklearn.compose import ColumnTransformer\n",
        "#ct = ColumnTransformer([(\"route\", OneHotEncoder(), [7])], remainder = 'passthrough')\n",
        "#df[\"route\"] = ct.fit_transform(df[\"route\"])\n",
        "\n",
        "onehotencoder.fit(df['route'].unique().reshape(-1, 1))\n",
        "\n",
        "transformed = onehotencoder.transform(df['route'].to_numpy().reshape(-1, 1))\n",
        "#Create a Pandas DataFrame of the hot encoded column\n",
        "ohe_df = pd.DataFrame(transformed, columns=onehotencoder.get_feature_names())\n",
        "#concat with original data\n",
        "data = pd.concat([df, ohe_df], axis=1).drop(['route'], axis=1)\n",
        "\n",
        "df.head()\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "DUCrD6mQPdY7",
        "outputId": "79fc267c-7d35-402a-ef5e-42d77f93588b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom sklearn.compose import ColumnTransformer\\n#ct = ColumnTransformer([(\"route\", OneHotEncoder(), [7])], remainder = \\'passthrough\\')\\n#df[\"route\"] = ct.fit_transform(df[\"route\"])\\n\\nonehotencoder.fit(df[\\'route\\'].unique().reshape(-1, 1))\\n\\ntransformed = onehotencoder.transform(df[\\'route\\'].to_numpy().reshape(-1, 1))\\n#Create a Pandas DataFrame of the hot encoded column\\nohe_df = pd.DataFrame(transformed, columns=onehotencoder.get_feature_names())\\n#concat with original data\\ndata = pd.concat([df, ohe_df], axis=1).drop([\\'route\\'], axis=1)\\n\\ndf.head()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cl = []\n",
        "for i in df.columns:\n",
        "  cl.append(i)\n",
        "\n",
        "print(cl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zaTU-ib-omO",
        "outputId": "94ee38e7-bf46-4ba8-8942-aee4cf6c0e5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['num_passengers', 'sales_channel', 'trip_type', 'purchase_lead', 'length_of_stay', 'flight_hour', 'wants_extra_baggage', 'wants_preferred_seat', 'wants_in_flight_meals', 'flight_duration', 'booking_complete', 'route_AKLDEL', 'route_AKLHGH', 'route_AKLHND', 'route_AKLICN', 'route_AKLKIX', 'route_AKLKTM', 'route_AKLKUL', 'route_AKLMRU', 'route_AKLPEK', 'route_AKLPVG', 'route_AKLTPE', 'route_AORICN', 'route_AORKIX', 'route_AORKTM', 'route_AORMEL', 'route_AORPER', 'route_AORPUS', 'route_BBIMEL', 'route_BBIOOL', 'route_BBIPER', 'route_BBISYD', 'route_BDOCTS', 'route_BDOCTU', 'route_BDOHGH', 'route_BDOICN', 'route_BDOIKA', 'route_BDOKIX', 'route_BDOMEL', 'route_BDOOOL', 'route_BDOPEK', 'route_BDOPER', 'route_BDOPUS', 'route_BDOPVG', 'route_BDOSYD', 'route_BDOTPE', 'route_BDOWUH', 'route_BDOXIY', 'route_BKICKG', 'route_BKICTS', 'route_BKICTU', 'route_BKIDEL', 'route_BKIHND', 'route_BKIICN', 'route_BKIKIX', 'route_BKIKTM', 'route_BKIMEL', 'route_BKIMRU', 'route_BKIOOL', 'route_BKIPEK', 'route_BKIPER', 'route_BKIPUS', 'route_BKIPVG', 'route_BKISYD', 'route_BKIXIY', 'route_BLRICN', 'route_BLRMEL', 'route_BLRPER', 'route_BLRSYD', 'route_BOMMEL', 'route_BOMOOL', 'route_BOMPER', 'route_BOMSYD', 'route_BTJJED', 'route_BTUCKG', 'route_BTUICN', 'route_BTUPER', 'route_BTUSYD', 'route_BTUWUH', 'route_BWNCKG', 'route_BWNDEL', 'route_BWNHGH', 'route_BWNIKA', 'route_BWNKTM', 'route_BWNMEL', 'route_BWNOOL', 'route_BWNPER', 'route_BWNSYD', 'route_BWNTPE', 'route_BWNWUH', 'route_CANDEL', 'route_CANIKA', 'route_CANMEL', 'route_CANMRU', 'route_CANOOL', 'route_CANPER', 'route_CANSYD', 'route_CCUMEL', 'route_CCUMRU', 'route_CCUOOL', 'route_CCUPER', 'route_CCUSYD', 'route_CCUTPE', 'route_CEBMEL', 'route_CEBOOL', 'route_CEBPER', 'route_CEBSYD', 'route_CGKCKG', 'route_CGKCTS', 'route_CGKCTU', 'route_CGKDEL', 'route_CGKHGH', 'route_CGKHND', 'route_CGKICN', 'route_CGKIKA', 'route_CGKJED', 'route_CGKKIX', 'route_CGKKTM', 'route_CGKMEL', 'route_CGKMRU', 'route_CGKOOL', 'route_CGKPEK', 'route_CGKPER', 'route_CGKPUS', 'route_CGKPVG', 'route_CGKSYD', 'route_CGKTPE', 'route_CGKWUH', 'route_CGKXIY', 'route_CKGCOK', 'route_CKGDPS', 'route_CKGHKT', 'route_CKGJHB', 'route_CKGKCH', 'route_CKGKNO', 'route_CKGLGK', 'route_CKGLOP', 'route_CKGMAA', 'route_CKGMEL', 'route_CKGMRU', 'route_CKGMYY', 'route_CKGOOL', 'route_CKGPEN', 'route_CKGPER', 'route_CKGPNH', 'route_CKGSBW', 'route_CKGSGN', 'route_CKGSIN', 'route_CKGSUB', 'route_CKGSYD', 'route_CKGTGG', 'route_CKGTRZ', 'route_CKGTWU', 'route_CMBCTS', 'route_CMBCTU', 'route_CMBHGH', 'route_CMBHND', 'route_CMBICN', 'route_CMBKIX', 'route_CMBMEL', 'route_CMBMRU', 'route_CMBOOL', 'route_CMBPEK', 'route_CMBPER', 'route_CMBPVG', 'route_CMBSYD', 'route_CMBWUH', 'route_CNXDEL', 'route_CNXHND', 'route_CNXICN', 'route_CNXKIX', 'route_CNXMEL', 'route_CNXOOL', 'route_CNXPEK', 'route_CNXPER', 'route_CNXPUS', 'route_CNXPVG', 'route_CNXSYD', 'route_CNXTPE', 'route_CNXXIY', 'route_COKCTS', 'route_COKCTU', 'route_COKHGH', 'route_COKICN', 'route_COKKIX', 'route_COKMEL', 'route_COKOOL', 'route_COKPER', 'route_COKPUS', 'route_COKSYD', 'route_COKTPE', 'route_COKWUH', 'route_CRKMEL', 'route_CRKOOL', 'route_CRKSYD', 'route_CSXMRU', 'route_CSXPER', 'route_CSXSYD', 'route_CTSDMK', 'route_CTSDPS', 'route_CTSHKT', 'route_CTSJHB', 'route_CTSJOG', 'route_CTSKBR', 'route_CTSKCH', 'route_CTSKNO', 'route_CTSLGK', 'route_CTSMEL', 'route_CTSMYY', 'route_CTSOOL', 'route_CTSPEN', 'route_CTSPER', 'route_CTSSBW', 'route_CTSSGN', 'route_CTSSIN', 'route_CTSSUB', 'route_CTSSYD', 'route_CTUDMK', 'route_CTUDPS', 'route_CTUHKT', 'route_CTUIKA', 'route_CTUJHB', 'route_CTUKBR', 'route_CTUKBV', 'route_CTUKCH', 'route_CTUKNO', 'route_CTULGK', 'route_CTULOP', 'route_CTUMAA', 'route_CTUMEL', 'route_CTUMLE', 'route_CTUMRU', 'route_CTUMYY', 'route_CTUOOL', 'route_CTUPEN', 'route_CTUPER', 'route_CTUREP', 'route_CTUSBW', 'route_CTUSGN', 'route_CTUSIN', 'route_CTUSRG', 'route_CTUSUB', 'route_CTUSYD', 'route_CTUTGG', 'route_CTUTRZ', 'route_CTUTWU', 'route_CTUURT', 'route_CXRMEL', 'route_DACHND', 'route_DACICN', 'route_DACKIX', 'route_DACMEL', 'route_DACMRU', 'route_DACOOL', 'route_DACPEK', 'route_DACPER', 'route_DACPUS', 'route_DACSYD', 'route_DACTPE', 'route_DADMEL', 'route_DADOOL', 'route_DADSYD', 'route_DELDMK', 'route_DELDPS', 'route_DELHKG', 'route_DELHKT', 'route_DELHND', 'route_DELJHB', 'route_DELJOG', 'route_DELKBR', 'route_DELKBV', 'route_DELKCH', 'route_DELKIX', 'route_DELKNO', 'route_DELLGK', 'route_DELMEL', 'route_DELMFM', 'route_DELMNL', 'route_DELMRU', 'route_DELMYY', 'route_DELOOL', 'route_DELPEN', 'route_DELPER', 'route_DELPNH', 'route_DELREP', 'route_DELRGN', 'route_DELSBW', 'route_DELSGN', 'route_DELSIN', 'route_DELSUB', 'route_DELSYD', 'route_DELSZX', 'route_DELURT', 'route_DMKHGH', 'route_DMKHND', 'route_DMKICN', 'route_DMKIKA', 'route_DMKKIX', 'route_DMKKTM', 'route_DMKMEL', 'route_DMKMRU', 'route_DMKOOL', 'route_DMKPEK', 'route_DMKPER', 'route_DMKPUS', 'route_DMKPVG', 'route_DMKSYD', 'route_DMKTPE', 'route_DPSHGH', 'route_DPSHND', 'route_DPSICN', 'route_DPSIKA', 'route_DPSKIX', 'route_DPSKTM', 'route_DPSMEL', 'route_DPSMRU', 'route_DPSOOL', 'route_DPSPEK', 'route_DPSPUS', 'route_DPSPVG', 'route_DPSSYD', 'route_DPSTPE', 'route_DPSWUH', 'route_DPSXIY', 'route_GOIKUL', 'route_GOIMEL', 'route_GOIOOL', 'route_GOIPER', 'route_GOISYD', 'route_HANKTM', 'route_HANMEL', 'route_HANOOL', 'route_HANPER', 'route_HANSYD', 'route_HDYHGH', 'route_HDYKIX', 'route_HDYKTM', 'route_HDYMEL', 'route_HDYOOL', 'route_HDYPEK', 'route_HDYPER', 'route_HDYPVG', 'route_HDYSYD', 'route_HDYTPE', 'route_HDYXIY', 'route_HGHHKT', 'route_HGHJHB', 'route_HGHJOG', 'route_HGHKBR', 'route_HGHKBV', 'route_HGHKCH', 'route_HGHKNO', 'route_HGHLGK', 'route_HGHLOP', 'route_HGHMAA', 'route_HGHMEL', 'route_HGHMRU', 'route_HGHMYY', 'route_HGHOOL', 'route_HGHPEN', 'route_HGHPER', 'route_HGHSBW', 'route_HGHSGN', 'route_HGHSIN', 'route_HGHSUB', 'route_HGHSYD', 'route_HGHTGG', 'route_HGHTRZ', 'route_HGHTWU', 'route_HKGIKA', 'route_HKGJED', 'route_HKGKTM', 'route_HKGMEL', 'route_HKGMRU', 'route_HKGOOL', 'route_HKGPER', 'route_HKGSYD', 'route_HKTHND', 'route_HKTICN', 'route_HKTIKA', 'route_HKTJED', 'route_HKTKIX', 'route_HKTKTM', 'route_HKTMEL', 'route_HKTMRU', 'route_HKTOOL', 'route_HKTPEK', 'route_HKTPER', 'route_HKTPUS', 'route_HKTPVG', 'route_HKTSYD', 'route_HKTTPE', 'route_HKTWUH', 'route_HKTXIY', 'route_HNDIKA', 'route_HNDJOG', 'route_HNDKBR', 'route_HNDKBV', 'route_HNDKCH', 'route_HNDKNO', 'route_HNDKTM', 'route_HNDLGK', 'route_HNDLOP', 'route_HNDMAA', 'route_HNDMEL', 'route_HNDMLE', 'route_HNDOOL', 'route_HNDPEN', 'route_HNDPER', 'route_HNDPNH', 'route_HNDREP', 'route_HNDRGN', 'route_HNDSBW', 'route_HNDSGN', 'route_HNDSIN', 'route_HNDSUB', 'route_HNDSYD', 'route_HNDTRZ', 'route_HYDMEL', 'route_HYDMRU', 'route_HYDOOL', 'route_HYDPER', 'route_HYDSYD', 'route_HYDWUH', 'route_ICNIKA', 'route_ICNJED', 'route_ICNJHB', 'route_ICNKBR', 'route_ICNKBV', 'route_ICNKCH', 'route_ICNKNO', 'route_ICNKTM', 'route_ICNLGK', 'route_ICNMAA', 'route_ICNMEL', 'route_ICNMLE', 'route_ICNMRU', 'route_ICNMYY', 'route_ICNOOL', 'route_ICNPEN', 'route_ICNPER', 'route_ICNREP', 'route_ICNRGN', 'route_ICNSBW', 'route_ICNSDK', 'route_ICNSGN', 'route_ICNSIN', 'route_ICNSUB', 'route_ICNSYD', 'route_ICNTGG', 'route_ICNTRZ', 'route_ICNVTE', 'route_ICNVTZ', 'route_IKAKCH', 'route_IKAKIX', 'route_IKAMEL', 'route_IKAMFM', 'route_IKAMNL', 'route_IKAOOL', 'route_IKAPEK', 'route_IKAPEN', 'route_IKAPER', 'route_IKAPUS', 'route_IKAPVG', 'route_IKASGN', 'route_IKASIN', 'route_IKASUB', 'route_IKASYD', 'route_IKASZX', 'route_IKATPE', 'route_JEDJOG', 'route_JEDKNO', 'route_JEDMEL', 'route_JEDMFM', 'route_JEDMNL', 'route_JEDPDG', 'route_JEDPEN', 'route_JEDSUB', 'route_JHBKIX', 'route_JHBKTM', 'route_JHBMEL', 'route_JHBMRU', 'route_JHBOOL', 'route_JHBPEK', 'route_JHBPUS', 'route_JHBPVG', 'route_JHBSYD', 'route_JHBTPE', 'route_JHBWUH', 'route_JHBXIY', 'route_JOGKIX', 'route_JOGKTM', 'route_JOGMEL', 'route_JOGOOL', 'route_JOGPER', 'route_JOGPVG', 'route_JOGSYD', 'route_JOGTPE', 'route_KBRKIX', 'route_KBRKTM', 'route_KBRMEL', 'route_KBROOL', 'route_KBRPEK', 'route_KBRPER', 'route_KBRPUS', 'route_KBRPVG', 'route_KBRSYD', 'route_KBRTPE', 'route_KBRWUH', 'route_KBRXIY', 'route_KBVKIX', 'route_KBVKTM', 'route_KBVMEL', 'route_KBVOOL', 'route_KBVPEK', 'route_KBVPER', 'route_KBVPUS', 'route_KBVPVG', 'route_KBVSYD', 'route_KBVTPE', 'route_KBVWUH', 'route_KBVXIY', 'route_KCHKIX', 'route_KCHKTM', 'route_KCHMEL', 'route_KCHOOL', 'route_KCHPEK', 'route_KCHPER', 'route_KCHPUS', 'route_KCHPVG', 'route_KCHSYD', 'route_KCHTPE', 'route_KCHWUH', 'route_KCHXIY', 'route_KHHMEL', 'route_KHHOOL', 'route_KHHPER', 'route_KHHSYD', 'route_KIXKNO', 'route_KIXKTM', 'route_KIXLBU', 'route_KIXLGK', 'route_KIXLOP', 'route_KIXLPQ', 'route_KIXMAA', 'route_KIXMEL', 'route_KIXMLE', 'route_KIXMRU', 'route_KIXMYY', 'route_KIXOOL', 'route_KIXPEN', 'route_KIXPER', 'route_KIXPNH', 'route_KIXREP', 'route_KIXRGN', 'route_KIXSBW', 'route_KIXSGN', 'route_KIXSIN', 'route_KIXSUB', 'route_KIXSYD', 'route_KIXTGG', 'route_KIXTRZ', 'route_KIXTWU', 'route_KLOMEL', 'route_KLOOOL', 'route_KLOSYD', 'route_KNOKTM', 'route_KNOMEL', 'route_KNOOOL', 'route_KNOPEK', 'route_KNOPER', 'route_KNOPUS', 'route_KNOPVG', 'route_KNOSYD', 'route_KNOTPE', 'route_KNOWUH', 'route_KNOXIY', 'route_KOSMEL', 'route_KOSOOL', 'route_KOSPEK', 'route_KOSSYD', 'route_KTMMEL', 'route_KTMMFM', 'route_KTMMYY', 'route_KTMPEN', 'route_KTMPER', 'route_KTMREP', 'route_KTMSGN', 'route_KTMSIN', 'route_KTMSUB', 'route_KTMSYD', 'route_KTMTPE', 'route_KTMTWU', 'route_KTMURT', 'route_KWLPER', 'route_LBUPER', 'route_LBUTPE', 'route_LGKMEL', 'route_LGKOOL', 'route_LGKPEK', 'route_LGKPER', 'route_LGKPUS', 'route_LGKPVG', 'route_LGKSYD', 'route_LGKTPE', 'route_LGKWUH', 'route_LGKXIY', 'route_LOPOOL', 'route_LOPPEK', 'route_LOPPER', 'route_LOPPVG', 'route_LOPSYD', 'route_LOPTPE', 'route_LOPXIY', 'route_LPQMEL', 'route_LPQOOL', 'route_LPQPER', 'route_LPQTPE', 'route_MAAMEL', 'route_MAAMRU', 'route_MAAOOL', 'route_MAAPER', 'route_MAAPVG', 'route_MAASYD', 'route_MAATPE', 'route_MAAWUH', 'route_MELMFM', 'route_MELMLE', 'route_MELMNL', 'route_MELMRU', 'route_MELMYY', 'route_MELNRT', 'route_MELPEK', 'route_MELPEN', 'route_MELPNH', 'route_MELPUS', 'route_MELPVG', 'route_MELREP', 'route_MELRGN', 'route_MELSBW', 'route_MELSGN', 'route_MELSIN', 'route_MELSUB', 'route_MELSWA', 'route_MELSZX', 'route_MELTGG', 'route_MELTPE', 'route_MELTRZ', 'route_MELTWU', 'route_MELURT', 'route_MELUTP', 'route_MELVTE', 'route_MELVTZ', 'route_MELWUH', 'route_MELXIY', 'route_MFMOOL', 'route_MFMPER', 'route_MFMSYD', 'route_MLEOOL', 'route_MLEPEK', 'route_MLEPER', 'route_MLEPVG', 'route_MLESYD', 'route_MLETPE', 'route_MNLMRU', 'route_MNLOOL', 'route_MNLPER', 'route_MNLSYD', 'route_MRUOOL', 'route_MRUPEK', 'route_MRUPEN', 'route_MRUPER', 'route_MRUPVG', 'route_MRUSGN', 'route_MRUSIN', 'route_MRUSUB', 'route_MRUSYD', 'route_MRUSZX', 'route_MRUTPE', 'route_MRUXIY', 'route_MYYOOL', 'route_MYYPER', 'route_MYYPUS', 'route_MYYSYD', 'route_MYYXIY', 'route_NRTSYD', 'route_OOLPEK', 'route_OOLPEN', 'route_OOLPNH', 'route_OOLPUS', 'route_OOLPVG', 'route_OOLREP', 'route_OOLRGN', 'route_OOLSBW', 'route_OOLSDK', 'route_OOLSGN', 'route_OOLSIN', 'route_OOLSUB', 'route_OOLSZX', 'route_OOLTGG', 'route_OOLTPE', 'route_OOLTRZ', 'route_OOLTWU', 'route_OOLURT', 'route_OOLUTP', 'route_OOLVTE', 'route_OOLXIY', 'route_PEKPEN', 'route_PEKPER', 'route_PEKREP', 'route_PEKRGN', 'route_PEKSBW', 'route_PEKSGN', 'route_PEKSIN', 'route_PEKSUB', 'route_PEKSYD', 'route_PEKTGG', 'route_PEKTRZ', 'route_PEKTWU', 'route_PENPER', 'route_PENPUS', 'route_PENPVG', 'route_PENSYD', 'route_PENTPE', 'route_PENWUH', 'route_PENXIY', 'route_PERPNH', 'route_PERPUS', 'route_PERPVG', 'route_PERREP', 'route_PERRGN', 'route_PERSBW', 'route_PERSDK', 'route_PERSGN', 'route_PERSIN', 'route_PERSUB', 'route_PERSWA', 'route_PERSZX', 'route_PERTGG', 'route_PERTPE', 'route_PERTRZ', 'route_PERTWU', 'route_PERUTP', 'route_PERVTE', 'route_PERVTZ', 'route_PERWUH', 'route_PERXIY', 'route_PNHSYD', 'route_PNHTPE', 'route_PNKTPE', 'route_PUSRGN', 'route_PUSSBW', 'route_PUSSGN', 'route_PUSSIN', 'route_PUSSUB', 'route_PUSSYD', 'route_PUSTRZ', 'route_PVGREP', 'route_PVGRGN', 'route_PVGSGN', 'route_PVGSIN', 'route_PVGSUB', 'route_PVGSYD', 'route_PVGTGG', 'route_PVGTWU', 'route_PVGURT', 'route_REPSYD', 'route_REPTPE', 'route_RGNSYD', 'route_RGNTPE', 'route_SBWSYD', 'route_SBWTPE', 'route_SBWWUH', 'route_SBWXIY', 'route_SDKSYD', 'route_SDKTPE', 'route_SGNSYD', 'route_SGNXIY', 'route_SINSYD', 'route_SINTPE', 'route_SINWUH', 'route_SINXIY', 'route_SRGTPE', 'route_SUBSYD', 'route_SUBTPE', 'route_SUBWUH', 'route_SUBXIY', 'route_SYDSZX', 'route_SYDTPE', 'route_SYDTRZ', 'route_SYDTWU', 'route_SYDVTE', 'route_SYDVTZ', 'route_SYDXIY', 'route_TGGTPE', 'route_TGGXIY', 'route_TPETRZ', 'route_TPETWU', 'route_TPEURT', 'route_TPEVTE', 'route_TRZXIY', 'route_TWUWUH', 'route_TWUXIY', 'route_URTXIY', 'booking_origin_(not set)', 'booking_origin_Afghanistan', 'booking_origin_Algeria', 'booking_origin_Argentina', 'booking_origin_Australia', 'booking_origin_Austria', 'booking_origin_Bahrain', 'booking_origin_Bangladesh', 'booking_origin_Belarus', 'booking_origin_Belgium', 'booking_origin_Bhutan', 'booking_origin_Brazil', 'booking_origin_Brunei', 'booking_origin_Bulgaria', 'booking_origin_Cambodia', 'booking_origin_Canada', 'booking_origin_Chile', 'booking_origin_China', 'booking_origin_Colombia', 'booking_origin_Croatia', 'booking_origin_Cyprus', 'booking_origin_Czech Republic', 'booking_origin_Czechia', 'booking_origin_Denmark', 'booking_origin_Egypt', 'booking_origin_Estonia', 'booking_origin_Finland', 'booking_origin_France', 'booking_origin_Germany', 'booking_origin_Ghana', 'booking_origin_Gibraltar', 'booking_origin_Greece', 'booking_origin_Guam', 'booking_origin_Guatemala', 'booking_origin_Hong Kong', 'booking_origin_Hungary', 'booking_origin_India', 'booking_origin_Indonesia', 'booking_origin_Iran', 'booking_origin_Iraq', 'booking_origin_Ireland', 'booking_origin_Israel', 'booking_origin_Italy', 'booking_origin_Japan', 'booking_origin_Jordan', 'booking_origin_Kazakhstan', 'booking_origin_Kenya', 'booking_origin_Kuwait', 'booking_origin_Laos', 'booking_origin_Lebanon', 'booking_origin_Macau', 'booking_origin_Malaysia', 'booking_origin_Maldives', 'booking_origin_Malta', 'booking_origin_Mauritius', 'booking_origin_Mexico', 'booking_origin_Mongolia', 'booking_origin_Myanmar (Burma)', 'booking_origin_Nepal', 'booking_origin_Netherlands', 'booking_origin_New Caledonia', 'booking_origin_New Zealand', 'booking_origin_Nicaragua', 'booking_origin_Norfolk Island', 'booking_origin_Norway', 'booking_origin_Oman', 'booking_origin_Pakistan', 'booking_origin_Panama', 'booking_origin_Papua New Guinea', 'booking_origin_Paraguay', 'booking_origin_Peru', 'booking_origin_Philippines', 'booking_origin_Poland', 'booking_origin_Portugal', 'booking_origin_Qatar', 'booking_origin_Romania', 'booking_origin_Russia', 'booking_origin_RÃ©union', 'booking_origin_Saudi Arabia', 'booking_origin_Seychelles', 'booking_origin_Singapore', 'booking_origin_Slovakia', 'booking_origin_Slovenia', 'booking_origin_Solomon Islands', 'booking_origin_South Africa', 'booking_origin_South Korea', 'booking_origin_Spain', 'booking_origin_Sri Lanka', 'booking_origin_Svalbard & Jan Mayen', 'booking_origin_Sweden', 'booking_origin_Switzerland', 'booking_origin_Taiwan', 'booking_origin_Tanzania', 'booking_origin_Thailand', 'booking_origin_Timor-Leste', 'booking_origin_Tunisia', 'booking_origin_Turkey', 'booking_origin_Ukraine', 'booking_origin_United Arab Emirates', 'booking_origin_United Kingdom', 'booking_origin_United States', 'booking_origin_Vanuatu', 'booking_origin_Vietnam', 'flight_day_Fri', 'flight_day_Mon', 'flight_day_Sat', 'flight_day_Sun', 'flight_day_Thu', 'flight_day_Tue', 'flight_day_Wed', 'flight_durtion']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "Ezy1qYXKHi4H",
        "outputId": "06afd9a2-94cf-4d1d-ce01-0562d3b0ac58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       num_passengers  sales_channel     trip_type  purchase_lead  \\\n",
              "count    44698.000000   44698.000000  44698.000000   44698.000000   \n",
              "mean         1.627634       0.882366      0.018882       0.101205   \n",
              "std          1.051234       0.322178      0.187421       0.106372   \n",
              "min          1.000000       0.000000      0.000000       0.000000   \n",
              "25%          1.000000       1.000000      0.000000       0.025375   \n",
              "50%          1.000000       1.000000      0.000000       0.061130   \n",
              "75%          2.000000       1.000000      0.000000       0.137255   \n",
              "max          9.000000       1.000000      2.000000       1.000000   \n",
              "\n",
              "       length_of_stay   flight_hour  wants_extra_baggage  \\\n",
              "count    44698.000000  44698.000000         44698.000000   \n",
              "mean         0.288378      0.396455             0.646942   \n",
              "std          0.241265      0.235887             0.477926   \n",
              "min          0.000000      0.000000             0.000000   \n",
              "25%          0.100000      0.217391             0.000000   \n",
              "50%          0.120000      0.391304             1.000000   \n",
              "75%          0.460000      0.565217             1.000000   \n",
              "max          0.980000      1.000000             1.000000   \n",
              "\n",
              "       wants_preferred_seat  wants_in_flight_meals  flight_duration  ...  \\\n",
              "count          44698.000000           44698.000000     44698.000000  ...   \n",
              "mean               0.294353               0.415388         7.246789  ...   \n",
              "std                0.455757               0.492794         1.483104  ...   \n",
              "min                0.000000               0.000000         4.670000  ...   \n",
              "25%                0.000000               0.000000         5.620000  ...   \n",
              "50%                0.000000               0.000000         7.420000  ...   \n",
              "75%                1.000000               1.000000         8.830000  ...   \n",
              "max                1.000000               1.000000         9.500000  ...   \n",
              "\n",
              "       booking_origin_Vanuatu  booking_origin_Vietnam  flight_day_Fri  \\\n",
              "count            44698.000000            44698.000000    44698.000000   \n",
              "mean                 0.000022                0.006667        0.134100   \n",
              "std                  0.004730                0.081380        0.340763   \n",
              "min                  0.000000                0.000000        0.000000   \n",
              "25%                  0.000000                0.000000        0.000000   \n",
              "50%                  0.000000                0.000000        0.000000   \n",
              "75%                  0.000000                0.000000        0.000000   \n",
              "max                  1.000000                1.000000        1.000000   \n",
              "\n",
              "       flight_day_Mon  flight_day_Sat  flight_day_Sun  flight_day_Thu  \\\n",
              "count    44698.000000    44698.000000    44698.000000    44698.000000   \n",
              "mean         0.162692        0.116001        0.132288        0.148553   \n",
              "std          0.369088        0.320229        0.338807        0.355651   \n",
              "min          0.000000        0.000000        0.000000        0.000000   \n",
              "25%          0.000000        0.000000        0.000000        0.000000   \n",
              "50%          0.000000        0.000000        0.000000        0.000000   \n",
              "75%          0.000000        0.000000        0.000000        0.000000   \n",
              "max          1.000000        1.000000        1.000000        1.000000   \n",
              "\n",
              "       flight_day_Tue  flight_day_Wed  flight_durtion  \n",
              "count    44698.000000    44698.000000    44698.000000  \n",
              "mean         0.153184        0.153184        0.762820  \n",
              "std          0.360168        0.360168        0.156116  \n",
              "min          0.000000        0.000000        0.491579  \n",
              "25%          0.000000        0.000000        0.591579  \n",
              "50%          0.000000        0.000000        0.781053  \n",
              "75%          0.000000        0.000000        0.929474  \n",
              "max          1.000000        1.000000        1.000000  \n",
              "\n",
              "[8 rows x 915 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-91c910bf-d91d-453a-9c26-cc6183ce8496\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_passengers</th>\n",
              "      <th>sales_channel</th>\n",
              "      <th>trip_type</th>\n",
              "      <th>purchase_lead</th>\n",
              "      <th>length_of_stay</th>\n",
              "      <th>flight_hour</th>\n",
              "      <th>wants_extra_baggage</th>\n",
              "      <th>wants_preferred_seat</th>\n",
              "      <th>wants_in_flight_meals</th>\n",
              "      <th>flight_duration</th>\n",
              "      <th>...</th>\n",
              "      <th>booking_origin_Vanuatu</th>\n",
              "      <th>booking_origin_Vietnam</th>\n",
              "      <th>flight_day_Fri</th>\n",
              "      <th>flight_day_Mon</th>\n",
              "      <th>flight_day_Sat</th>\n",
              "      <th>flight_day_Sun</th>\n",
              "      <th>flight_day_Thu</th>\n",
              "      <th>flight_day_Tue</th>\n",
              "      <th>flight_day_Wed</th>\n",
              "      <th>flight_durtion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>44698.000000</td>\n",
              "      <td>44698.000000</td>\n",
              "      <td>44698.000000</td>\n",
              "      <td>44698.000000</td>\n",
              "      <td>44698.000000</td>\n",
              "      <td>44698.000000</td>\n",
              "      <td>44698.000000</td>\n",
              "      <td>44698.000000</td>\n",
              "      <td>44698.000000</td>\n",
              "      <td>44698.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>44698.000000</td>\n",
              "      <td>44698.000000</td>\n",
              "      <td>44698.000000</td>\n",
              "      <td>44698.000000</td>\n",
              "      <td>44698.000000</td>\n",
              "      <td>44698.000000</td>\n",
              "      <td>44698.000000</td>\n",
              "      <td>44698.000000</td>\n",
              "      <td>44698.000000</td>\n",
              "      <td>44698.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.627634</td>\n",
              "      <td>0.882366</td>\n",
              "      <td>0.018882</td>\n",
              "      <td>0.101205</td>\n",
              "      <td>0.288378</td>\n",
              "      <td>0.396455</td>\n",
              "      <td>0.646942</td>\n",
              "      <td>0.294353</td>\n",
              "      <td>0.415388</td>\n",
              "      <td>7.246789</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0.006667</td>\n",
              "      <td>0.134100</td>\n",
              "      <td>0.162692</td>\n",
              "      <td>0.116001</td>\n",
              "      <td>0.132288</td>\n",
              "      <td>0.148553</td>\n",
              "      <td>0.153184</td>\n",
              "      <td>0.153184</td>\n",
              "      <td>0.762820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.051234</td>\n",
              "      <td>0.322178</td>\n",
              "      <td>0.187421</td>\n",
              "      <td>0.106372</td>\n",
              "      <td>0.241265</td>\n",
              "      <td>0.235887</td>\n",
              "      <td>0.477926</td>\n",
              "      <td>0.455757</td>\n",
              "      <td>0.492794</td>\n",
              "      <td>1.483104</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004730</td>\n",
              "      <td>0.081380</td>\n",
              "      <td>0.340763</td>\n",
              "      <td>0.369088</td>\n",
              "      <td>0.320229</td>\n",
              "      <td>0.338807</td>\n",
              "      <td>0.355651</td>\n",
              "      <td>0.360168</td>\n",
              "      <td>0.360168</td>\n",
              "      <td>0.156116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.670000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.491579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025375</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.620000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.591579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.061130</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>0.391304</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.420000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.781053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.137255</td>\n",
              "      <td>0.460000</td>\n",
              "      <td>0.565217</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.830000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.929474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 915 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91c910bf-d91d-453a-9c26-cc6183ce8496')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-91c910bf-d91d-453a-9c26-cc6183ce8496 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-91c910bf-d91d-453a-9c26-cc6183ce8496');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.models import Sequential, load_model\n",
        "import numpy as np\n",
        "\n"
      ],
      "metadata": {
        "id": "xcdSEERZQbnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Predictors=['num_passengers',\t'sales_channel',\t'trip_type',\t'purchase_lead',\t'length_of_stay',\t'flight_hour',\t'wants_extra_baggage',\t'wants_preferred_seat',\t'wants_in_flight_meals',\t'flight_duration', 'route_AKLHGH', 'route_AKLHND', 'route_AKLICN', 'route_AKLKIX', 'route_AKLKTM', 'route_AKLKUL', 'route_AKLMRU', 'route_AKLPEK', 'route_AKLPVG', 'route_AKLTPE', 'route_AORICN', 'route_AORKIX', 'route_AORKTM', 'route_AORMEL', 'route_AORPER', 'route_AORPUS', 'route_BBIMEL', 'route_BBIOOL', 'route_BBIPER', 'route_BBISYD', 'route_BDOCTS', 'route_BDOCTU', 'route_BDOHGH', 'route_BDOICN', 'route_BDOIKA', 'route_BDOKIX', 'route_BDOMEL', 'route_BDOOOL', 'route_BDOPEK', 'route_BDOPER', 'route_BDOPUS', 'route_BDOPVG', 'route_BDOSYD', 'route_BDOTPE', 'route_BDOWUH', 'route_BDOXIY', 'route_BKICKG', 'route_BKICTS', 'route_BKICTU', 'route_BKIDEL', 'route_BKIHND', 'route_BKIICN', 'route_BKIKIX', 'route_BKIKTM', 'route_BKIMEL', 'route_BKIMRU', 'route_BKIOOL', 'route_BKIPEK', 'route_BKIPER', 'route_BKIPUS', 'route_BKIPVG', 'route_BKISYD', 'route_BKIXIY', 'route_BLRICN', 'route_BLRMEL', 'route_BLRPER', 'route_BLRSYD', 'route_BOMMEL', 'route_BOMOOL', 'route_BOMPER', 'route_BOMSYD', 'route_BTJJED', 'route_BTUCKG', 'route_BTUICN', 'route_BTUPER', 'route_BTUSYD', 'route_BTUWUH', 'route_BWNCKG', 'route_BWNDEL', 'route_BWNHGH', 'route_BWNIKA', 'route_BWNKTM', 'route_BWNMEL', 'route_BWNOOL', 'route_BWNPER', 'route_BWNSYD', 'route_BWNTPE', 'route_BWNWUH', 'route_CANDEL', 'route_CANIKA', 'route_CANMEL', 'route_CANMRU', 'route_CANOOL', 'route_CANPER', 'route_CANSYD', 'route_CCUMEL', 'route_CCUMRU', 'route_CCUOOL', 'route_CCUPER', 'route_CCUSYD', 'route_CCUTPE', 'route_CEBMEL', 'route_CEBOOL', 'route_CEBPER', 'route_CEBSYD', 'route_CGKCKG', 'route_CGKCTS', 'route_CGKCTU', 'route_CGKDEL', 'route_CGKHGH', 'route_CGKHND', 'route_CGKICN', 'route_CGKIKA', 'route_CGKJED', 'route_CGKKIX', 'route_CGKKTM', 'route_CGKMEL', 'route_CGKMRU', 'route_CGKOOL', 'route_CGKPEK', 'route_CGKPER', 'route_CGKPUS', 'route_CGKPVG', 'route_CGKSYD', 'route_CGKTPE', 'route_CGKWUH', 'route_CGKXIY', 'route_CKGCOK', 'route_CKGDPS', 'route_CKGHKT', 'route_CKGJHB', 'route_CKGKCH', 'route_CKGKNO', 'route_CKGLGK', 'route_CKGLOP', 'route_CKGMAA', 'route_CKGMEL', 'route_CKGMRU', 'route_CKGMYY', 'route_CKGOOL', 'route_CKGPEN', 'route_CKGPER', 'route_CKGPNH', 'route_CKGSBW', 'route_CKGSGN', 'route_CKGSIN', 'route_CKGSUB', 'route_CKGSYD', 'route_CKGTGG', 'route_CKGTRZ', 'route_CKGTWU', 'route_CMBCTS', 'route_CMBCTU', 'route_CMBHGH', 'route_CMBHND', 'route_CMBICN', 'route_CMBKIX', 'route_CMBMEL', 'route_CMBMRU', 'route_CMBOOL', 'route_CMBPEK', 'route_CMBPER', 'route_CMBPVG', 'route_CMBSYD', 'route_CMBWUH', 'route_CNXDEL', 'route_CNXHND', 'route_CNXICN', 'route_CNXKIX', 'route_CNXMEL', 'route_CNXOOL', 'route_CNXPEK', 'route_CNXPER', 'route_CNXPUS', 'route_CNXPVG', 'route_CNXSYD', 'route_CNXTPE', 'route_CNXXIY', 'route_COKCTS', 'route_COKCTU', 'route_COKHGH', 'route_COKICN', 'route_COKKIX', 'route_COKMEL', 'route_COKOOL', 'route_COKPER', 'route_COKPUS', 'route_COKSYD', 'route_COKTPE', 'route_COKWUH', 'route_CRKMEL', 'route_CRKOOL', 'route_CRKSYD', 'route_CSXMRU', 'route_CSXPER', 'route_CSXSYD', 'route_CTSDMK', 'route_CTSDPS', 'route_CTSHKT', 'route_CTSJHB', 'route_CTSJOG', 'route_CTSKBR', 'route_CTSKCH', 'route_CTSKNO', 'route_CTSLGK', 'route_CTSMEL', 'route_CTSMYY', 'route_CTSOOL', 'route_CTSPEN', 'route_CTSPER', 'route_CTSSBW', 'route_CTSSGN', 'route_CTSSIN', 'route_CTSSUB', 'route_CTSSYD', 'route_CTUDMK', 'route_CTUDPS', 'route_CTUHKT', 'route_CTUIKA', 'route_CTUJHB', 'route_CTUKBR', 'route_CTUKBV', 'route_CTUKCH', 'route_CTUKNO', 'route_CTULGK', 'route_CTULOP', 'route_CTUMAA', 'route_CTUMEL', 'route_CTUMLE', 'route_CTUMRU', 'route_CTUMYY', 'route_CTUOOL', 'route_CTUPEN', 'route_CTUPER', 'route_CTUREP', 'route_CTUSBW', 'route_CTUSGN', 'route_CTUSIN', 'route_CTUSRG', 'route_CTUSUB', 'route_CTUSYD', 'route_CTUTGG', 'route_CTUTRZ', 'route_CTUTWU', 'route_CTUURT', 'route_CXRMEL', 'route_DACHND', 'route_DACICN', 'route_DACKIX', 'route_DACMEL', 'route_DACMRU', 'route_DACOOL', 'route_DACPEK', 'route_DACPER', 'route_DACPUS', 'route_DACSYD', 'route_DACTPE', 'route_DADMEL', 'route_DADOOL', 'route_DADSYD', 'route_DELDMK', 'route_DELDPS', 'route_DELHKG', 'route_DELHKT', 'route_DELHND', 'route_DELJHB', 'route_DELJOG', 'route_DELKBR', 'route_DELKBV', 'route_DELKCH', 'route_DELKIX', 'route_DELKNO', 'route_DELLGK', 'route_DELMEL', 'route_DELMFM', 'route_DELMNL', 'route_DELMRU', 'route_DELMYY', 'route_DELOOL', 'route_DELPEN', 'route_DELPER', 'route_DELPNH', 'route_DELREP', 'route_DELRGN', 'route_DELSBW', 'route_DELSGN', 'route_DELSIN', 'route_DELSUB', 'route_DELSYD', 'route_DELSZX', 'route_DELURT', 'route_DMKHGH', 'route_DMKHND', 'route_DMKICN', 'route_DMKIKA', 'route_DMKKIX', 'route_DMKKTM', 'route_DMKMEL', 'route_DMKMRU', 'route_DMKOOL', 'route_DMKPEK', 'route_DMKPER', 'route_DMKPUS', 'route_DMKPVG', 'route_DMKSYD', 'route_DMKTPE', 'route_DPSHGH', 'route_DPSHND', 'route_DPSICN', 'route_DPSIKA', 'route_DPSKIX', 'route_DPSKTM', 'route_DPSMEL', 'route_DPSMRU', 'route_DPSOOL', 'route_DPSPEK', 'route_DPSPUS', 'route_DPSPVG', 'route_DPSSYD', 'route_DPSTPE', 'route_DPSWUH', 'route_DPSXIY', 'route_GOIKUL', 'route_GOIMEL', 'route_GOIOOL', 'route_GOIPER', 'route_GOISYD', 'route_HANKTM', 'route_HANMEL', 'route_HANOOL', 'route_HANPER', 'route_HANSYD', 'route_HDYHGH', 'route_HDYKIX', 'route_HDYKTM', 'route_HDYMEL', 'route_HDYOOL', 'route_HDYPEK', 'route_HDYPER', 'route_HDYPVG', 'route_HDYSYD', 'route_HDYTPE', 'route_HDYXIY', 'route_HGHHKT', 'route_HGHJHB', 'route_HGHJOG', 'route_HGHKBR', 'route_HGHKBV', 'route_HGHKCH', 'route_HGHKNO', 'route_HGHLGK', 'route_HGHLOP', 'route_HGHMAA', 'route_HGHMEL', 'route_HGHMRU', 'route_HGHMYY', 'route_HGHOOL', 'route_HGHPEN', 'route_HGHPER', 'route_HGHSBW', 'route_HGHSGN', 'route_HGHSIN', 'route_HGHSUB', 'route_HGHSYD', 'route_HGHTGG', 'route_HGHTRZ', 'route_HGHTWU', 'route_HKGIKA', 'route_HKGJED', 'route_HKGKTM', 'route_HKGMEL', 'route_HKGMRU', 'route_HKGOOL', 'route_HKGPER', 'route_HKGSYD', 'route_HKTHND', 'route_HKTICN', 'route_HKTIKA', 'route_HKTJED', 'route_HKTKIX', 'route_HKTKTM', 'route_HKTMEL', 'route_HKTMRU', 'route_HKTOOL', 'route_HKTPEK', 'route_HKTPER', 'route_HKTPUS', 'route_HKTPVG', 'route_HKTSYD', 'route_HKTTPE', 'route_HKTWUH', 'route_HKTXIY', 'route_HNDIKA', 'route_HNDJOG', 'route_HNDKBR', 'route_HNDKBV', 'route_HNDKCH', 'route_HNDKNO', 'route_HNDKTM', 'route_HNDLGK', 'route_HNDLOP', 'route_HNDMAA', 'route_HNDMEL', 'route_HNDMLE', 'route_HNDOOL', 'route_HNDPEN', 'route_HNDPER', 'route_HNDPNH', 'route_HNDREP', 'route_HNDRGN', 'route_HNDSBW', 'route_HNDSGN', 'route_HNDSIN', 'route_HNDSUB', 'route_HNDSYD', 'route_HNDTRZ', 'route_HYDMEL', 'route_HYDMRU', 'route_HYDOOL', 'route_HYDPER', 'route_HYDSYD', 'route_HYDWUH', 'route_ICNIKA', 'route_ICNJED', 'route_ICNJHB', 'route_ICNKBR', 'route_ICNKBV', 'route_ICNKCH', 'route_ICNKNO', 'route_ICNKTM', 'route_ICNLGK', 'route_ICNMAA', 'route_ICNMEL', 'route_ICNMLE', 'route_ICNMRU', 'route_ICNMYY', 'route_ICNOOL', 'route_ICNPEN', 'route_ICNPER', 'route_ICNREP', 'route_ICNRGN', 'route_ICNSBW', 'route_ICNSDK', 'route_ICNSGN', 'route_ICNSIN', 'route_ICNSUB', 'route_ICNSYD', 'route_ICNTGG', 'route_ICNTRZ', 'route_ICNVTE', 'route_ICNVTZ', 'route_IKAKCH', 'route_IKAKIX',  'route_IKAMEL', 'route_IKAMFM', 'route_IKAMNL', 'route_IKAOOL', 'route_IKAPEK', 'route_IKAPEN', 'route_IKAPER', 'route_IKAPUS', 'route_IKAPVG', 'route_IKASGN', 'route_IKASIN', 'route_IKASUB', 'route_IKASYD', 'route_IKASZX', 'route_IKATPE', 'route_JEDJOG', 'route_JEDKNO', 'route_JEDMEL', 'route_JEDMFM', 'route_JEDMNL', 'route_JEDPDG', 'route_JEDPEN', 'route_JEDSUB', 'route_JHBKIX', 'route_JHBKTM', 'route_JHBMEL', 'route_JHBMRU', 'route_JHBOOL', 'route_JHBPEK', 'route_JHBPUS', 'route_JHBPVG', 'route_JHBSYD', 'route_JHBTPE', 'route_JHBWUH', 'route_JHBXIY', 'route_JOGKIX', 'route_JOGKTM', 'route_JOGMEL', 'route_JOGOOL', 'route_JOGPER', 'route_JOGPVG', 'route_JOGSYD', 'route_JOGTPE', 'route_KBRKIX', 'route_KBRKTM', 'route_KBRMEL', 'route_KBROOL', 'route_KBRPEK', 'route_KBRPER', 'route_KBRPUS', 'route_KBRPVG', 'route_KBRSYD', 'route_KBRTPE', 'route_KBRWUH', 'route_KBRXIY', 'route_KBVKIX', 'route_KBVKTM', 'route_KBVMEL', 'route_KBVOOL', 'route_KBVPEK', 'route_KBVPER', 'route_KBVPUS', 'route_KBVPVG', 'route_KBVSYD', 'route_KBVTPE', 'route_KBVWUH', 'route_KBVXIY', 'route_KCHKIX', 'route_KCHKTM', 'route_KCHMEL', 'route_KCHOOL', 'route_KCHPEK', 'route_KCHPER', 'route_KCHPUS', 'route_KCHPVG', 'route_KCHSYD', 'route_KCHTPE', 'route_KCHWUH', 'route_KCHXIY', 'route_KHHMEL', 'route_KHHOOL', 'route_KHHPER', 'route_KHHSYD', 'route_KIXKNO', 'route_KIXKTM', 'route_KIXLBU', 'route_KIXLGK', 'route_KIXLOP', 'route_KIXLPQ', 'route_KIXMAA', 'route_KIXMEL', 'route_KIXMLE', 'route_KIXMRU', 'route_KIXMYY', 'route_KIXOOL', 'route_KIXPEN', 'route_KIXPER', 'route_KIXPNH', 'route_KIXREP', 'route_KIXRGN', 'route_KIXSBW', 'route_KIXSGN', 'route_KIXSIN', 'route_KIXSUB', 'route_KIXSYD', 'route_KIXTGG', 'route_KIXTRZ', 'route_KIXTWU', 'route_KLOMEL', 'route_KLOOOL', 'route_KLOSYD', 'route_KNOKTM', 'route_KNOMEL', 'route_KNOOOL', 'route_KNOPEK', 'route_KNOPER', 'route_KNOPUS', 'route_KNOPVG', 'route_KNOSYD', 'route_KNOTPE', 'route_KNOWUH', 'route_KNOXIY', 'route_KOSMEL', 'route_KOSOOL', 'route_KOSPEK', 'route_KOSSYD', 'route_KTMMEL', 'route_KTMMFM', 'route_KTMMYY', 'route_KTMPEN', 'route_KTMPER', 'route_KTMREP', 'route_KTMSGN', 'route_KTMSIN', 'route_KTMSUB', 'route_KTMSYD', 'route_KTMTPE', 'route_KTMTWU', 'route_KTMURT', 'route_KWLPER', 'route_LBUPER', 'route_LBUTPE', 'route_LGKMEL', 'route_LGKOOL', 'route_LGKPEK', 'route_LGKPER', 'route_LGKPUS', 'route_LGKPVG', 'route_LGKSYD', 'route_LGKTPE', 'route_LGKWUH', 'route_LGKXIY', 'route_LOPOOL', 'route_LOPPEK', 'route_LOPPER', 'route_LOPPVG', 'route_LOPSYD', 'route_LOPTPE', 'route_LOPXIY', 'route_LPQMEL', 'route_LPQOOL', 'route_LPQPER', 'route_LPQTPE', 'route_MAAMEL', 'route_MAAMRU', 'route_MAAOOL', 'route_MAAPER', 'route_MAAPVG', 'route_MAASYD', 'route_MAATPE', 'route_MAAWUH', 'route_MELMFM', 'route_MELMLE', 'route_MELMNL', 'route_MELMRU', 'route_MELMYY', 'route_MELNRT', 'route_MELPEK', 'route_MELPEN', 'route_MELPNH', 'route_MELPUS', 'route_MELPVG', 'route_MELREP', 'route_MELRGN', 'route_MELSBW', 'route_MELSGN', 'route_MELSIN', 'route_MELSUB', 'route_MELSWA', 'route_MELSZX', 'route_MELTGG', 'route_MELTPE', 'route_MELTRZ', 'route_MELTWU', 'route_MELURT', 'route_MELUTP', 'route_MELVTE', 'route_MELVTZ', 'route_MELWUH', 'route_MELXIY', 'route_MFMOOL', 'route_MFMPER', 'route_MFMSYD', 'route_MLEOOL', 'route_MLEPEK', 'route_MLEPER', 'route_MLEPVG', 'route_MLESYD', 'route_MLETPE', 'route_MNLMRU', 'route_MNLOOL', 'route_MNLPER', 'route_MNLSYD', 'route_MRUOOL', 'route_MRUPEK', 'route_MRUPEN', 'route_MRUPER', 'route_MRUPVG', 'route_MRUSGN', 'route_MRUSIN', 'route_MRUSUB', 'route_MRUSYD', 'route_MRUSZX', 'route_MRUTPE', 'route_MRUXIY', 'route_MYYOOL', 'route_MYYPER', 'route_MYYPUS', 'route_MYYSYD', 'route_MYYXIY', 'route_NRTSYD', 'route_OOLPEK', 'route_OOLPEN', 'route_OOLPNH', 'route_OOLPUS', 'route_OOLPVG', 'route_OOLREP', 'route_OOLRGN', 'route_OOLSBW', 'route_OOLSDK', 'route_OOLSGN', 'route_OOLSIN', 'route_OOLSUB', 'route_OOLSZX', 'route_OOLTGG', 'route_OOLTPE', 'route_OOLTRZ', 'route_OOLTWU', 'route_OOLURT', 'route_OOLUTP', 'route_OOLVTE', 'route_OOLXIY', 'route_PEKPEN', 'route_PEKPER', 'route_PEKREP', 'route_PEKRGN', 'route_PEKSBW', 'route_PEKSGN', 'route_PEKSIN', 'route_PEKSUB', 'route_PEKSYD', 'route_PEKTGG', 'route_PEKTRZ', 'route_PEKTWU', 'route_PENPER', 'route_PENPUS', 'route_PENPVG', 'route_PENSYD', 'route_PENTPE', 'route_PENWUH', 'route_PENXIY', 'route_PERPNH', 'route_PERPUS', 'route_PERPVG', 'route_PERREP', 'route_PERRGN', 'route_PERSBW', 'route_PERSDK', 'route_PERSGN', 'route_PERSIN', 'route_PERSUB', 'route_PERSWA', 'route_PERSZX', 'route_PERTGG', 'route_PERTPE', 'route_PERTRZ', 'route_PERTWU', 'route_PERUTP', 'route_PERVTE', 'route_PERVTZ', 'route_PERWUH', 'route_PERXIY', 'route_PNHSYD', 'route_PNHTPE', 'route_PNKTPE', 'route_PUSRGN', 'route_PUSSBW', 'route_PUSSGN', 'route_PUSSIN', 'route_PUSSUB', 'route_PUSSYD', 'route_PUSTRZ', 'route_PVGREP', 'route_PVGRGN', 'route_PVGSGN', 'route_PVGSIN', 'route_PVGSUB', 'route_PVGSYD', 'route_PVGTGG', 'route_PVGTWU', 'route_PVGURT', 'route_REPSYD', 'route_REPTPE', 'route_RGNSYD', 'route_RGNTPE', 'route_SBWSYD', 'route_SBWTPE', 'route_SBWWUH', 'route_SBWXIY', 'route_SDKSYD', 'route_SDKTPE', 'route_SGNSYD', 'route_SGNXIY', 'route_SINSYD', 'route_SINTPE', 'route_SINWUH', 'route_SINXIY', 'route_SRGTPE', 'route_SUBSYD', 'route_SUBTPE', 'route_SUBWUH', 'route_SUBXIY', 'route_SYDSZX', 'route_SYDTPE', 'route_SYDTRZ', 'route_SYDTWU', 'route_SYDVTE', 'route_SYDVTZ', 'route_SYDXIY', 'route_TGGTPE', 'route_TGGXIY', 'route_TPETRZ', 'route_TPETWU', 'route_TPEURT', 'route_TPEVTE', 'route_TRZXIY', 'route_TWUWUH', 'route_TWUXIY', 'route_URTXIY','booking_origin_Afghanistan', 'booking_origin_Algeria', 'booking_origin_Argentina', 'booking_origin_Australia', 'booking_origin_Austria', 'booking_origin_Bahrain', 'booking_origin_Bangladesh', 'booking_origin_Belarus', 'booking_origin_Belgium', 'booking_origin_Bhutan', 'booking_origin_Brazil', 'booking_origin_Brunei', 'booking_origin_Bulgaria', 'booking_origin_Cambodia', 'booking_origin_Canada', 'booking_origin_Chile', 'booking_origin_China', 'booking_origin_Colombia', 'booking_origin_Croatia', 'booking_origin_Cyprus', 'booking_origin_Czech Republic', 'booking_origin_Czechia', 'booking_origin_Denmark', 'booking_origin_Egypt', 'booking_origin_Estonia', 'booking_origin_Finland', 'booking_origin_France', 'booking_origin_Germany', 'booking_origin_Ghana', 'booking_origin_Gibraltar', 'booking_origin_Greece', 'booking_origin_Guam', 'booking_origin_Guatemala', 'booking_origin_Hong Kong', 'booking_origin_Hungary', 'booking_origin_India', 'booking_origin_Indonesia', 'booking_origin_Iran', 'booking_origin_Iraq', 'booking_origin_Ireland', 'booking_origin_Israel', 'booking_origin_Italy', 'booking_origin_Japan', 'booking_origin_Jordan', 'booking_origin_Kazakhstan', 'booking_origin_Kenya', 'booking_origin_Kuwait', 'booking_origin_Laos', 'booking_origin_Lebanon', 'booking_origin_Macau', 'booking_origin_Malaysia', 'booking_origin_Maldives', 'booking_origin_Malta', 'booking_origin_Mauritius', 'booking_origin_Mexico', 'booking_origin_Mongolia', 'booking_origin_Myanmar (Burma)', 'booking_origin_Nepal', 'booking_origin_Netherlands', 'booking_origin_New Caledonia', 'booking_origin_New Zealand', 'booking_origin_Nicaragua', 'booking_origin_Norfolk Island', 'booking_origin_Norway', 'booking_origin_Oman', 'booking_origin_Pakistan', 'booking_origin_Panama', 'booking_origin_Papua New Guinea', 'booking_origin_Paraguay', 'booking_origin_Peru', 'booking_origin_Philippines', 'booking_origin_Poland', 'booking_origin_Portugal', 'booking_origin_Qatar', 'booking_origin_Romania', 'booking_origin_Russia', 'booking_origin_RÃ©union', 'booking_origin_Saudi Arabia', 'booking_origin_Seychelles', 'booking_origin_Singapore', 'booking_origin_Slovakia', 'booking_origin_Slovenia', 'booking_origin_Solomon Islands', 'booking_origin_South Africa', 'booking_origin_South Korea', 'booking_origin_Spain', 'booking_origin_Sri Lanka', 'booking_origin_Svalbard & Jan Mayen', 'booking_origin_Sweden', 'booking_origin_Switzerland', 'booking_origin_Taiwan', 'booking_origin_Tanzania', 'booking_origin_Thailand', 'booking_origin_Timor-Leste', 'booking_origin_Tunisia', 'booking_origin_Turkey', 'booking_origin_Ukraine', 'booking_origin_United Arab Emirates', 'booking_origin_United Kingdom', 'booking_origin_United States', 'booking_origin_Vanuatu', 'booking_origin_Vietnam', 'flight_day_Fri', 'flight_day_Mon', 'flight_day_Sat', 'flight_day_Sun', 'flight_day_Thu', 'flight_day_Tue', 'flight_day_Wed']\n",
        "\n",
        "TargetVariable = ['booking_complete']\n",
        "\n",
        "\n",
        "X=df[Predictors].values\n",
        "y=df[TargetVariable].values\n",
        "### Sandardization of data ###\n",
        "### We does not standardize the Target variable for classification\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "PredictorScaler=StandardScaler()\n",
        " \n",
        "# Storing the fit object for later reference\n",
        "PredictorScalerFit=PredictorScaler.fit(X)\n",
        " \n",
        "# Generating the standardized values of X and y\n",
        "X=PredictorScalerFit.transform(X)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "FPc0n5-IPxkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbAWcDIUEAnn",
        "outputId": "31451602-fb22-4e41-b933-eaf9df94d664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0]\n",
            " [0]\n",
            " [1]\n",
            " ...\n",
            " [0]\n",
            " [1]\n",
            " [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow scikeras scikit-learn"
      ],
      "metadata": {
        "id": "tFJS6RoLttZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89855c4e-82df-4a09-db93-a01eccc3c7ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.9.2)\n",
            "Requirement already satisfied: scikeras in /usr/local/lib/python3.8/dist-packages (0.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.0.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.29.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.25.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (6.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import read_csv\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "# load dataset\n",
        "dataset = df.values\n",
        "# split into input (X) and output (Y) variables\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# larger model\n",
        "def create_larger():\n",
        " # create model\n",
        " model = Sequential()\n",
        " model.add(Dense(10, input_shape=(912,), activation='relu'))\n",
        " model.add(Dense(5, activation='relu'))\n",
        " model.add(Dense(1, activation='exponential'))\n",
        " # Compile model\n",
        " model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'], class_weight = class_weights)\n",
        " return model\n"
      ],
      "metadata": {
        "id": "yKE0LbS6qYwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import datasets, layers, models\n"
      ],
      "metadata": {
        "id": "E9Pw4GOjMfOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.constraints import MaxNorm\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dropout(0.1, input_shape=(911,)))\n",
        "\n",
        "\n",
        "model.add(Dense(30, activation='softmax',kernel_constraint=MaxNorm(3)))\n",
        "#model.add(Dense(10, activation='softmax',kernel_constraint=MaxNorm(3)))\n",
        "model.add(Dense(5, activation='softmax',kernel_constraint=MaxNorm(3)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.utils import class_weight\n",
        "opt = keras.optimizers.Adam(lr=0.0001, decay=1e-6)\n",
        "\n",
        "y_ints = [int(y) for y in y_train]\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 classes = np.unique(y_ints),\n",
        "                                                 y = y_ints)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=opt, \n",
        "              loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "#print(y_ints)\n",
        "history = model.fit(X_train,y_train, epochs=300, \n",
        "                    validation_data=(X_test, y_test), shuffle = True, class_weight = class_weights)\n",
        "#history = model.fit(X_train, y_train,  verbose = 2, validation_data = (X_test, y_test), class_weight=class_weights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlUJLUBEMgU3",
        "outputId": "b46499b3-d707-4fac-f33d-263973e365a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "1118/1118 [==============================] - 7s 6ms/step - loss: 0.7045 - accuracy: 0.1510 - val_loss: 0.7757 - val_accuracy: 0.1490\n",
            "Epoch 2/300\n",
            "1118/1118 [==============================] - 8s 7ms/step - loss: 0.6875 - accuracy: 0.1513 - val_loss: 0.7205 - val_accuracy: 0.1521\n",
            "Epoch 3/300\n",
            "1118/1118 [==============================] - 11s 10ms/step - loss: 0.6735 - accuracy: 0.4734 - val_loss: 0.6851 - val_accuracy: 0.6285\n",
            "Epoch 4/300\n",
            "1118/1118 [==============================] - 7s 6ms/step - loss: 0.6594 - accuracy: 0.6572 - val_loss: 0.6584 - val_accuracy: 0.6764\n",
            "Epoch 5/300\n",
            "1118/1118 [==============================] - 4s 3ms/step - loss: 0.6451 - accuracy: 0.6840 - val_loss: 0.6362 - val_accuracy: 0.6932\n",
            "Epoch 6/300\n",
            "1118/1118 [==============================] - 4s 3ms/step - loss: 0.6303 - accuracy: 0.6974 - val_loss: 0.6187 - val_accuracy: 0.6987\n",
            "Epoch 7/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.6172 - accuracy: 0.7030 - val_loss: 0.6025 - val_accuracy: 0.7038\n",
            "Epoch 8/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.6062 - accuracy: 0.7066 - val_loss: 0.5932 - val_accuracy: 0.7074\n",
            "Epoch 9/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5970 - accuracy: 0.7110 - val_loss: 0.5884 - val_accuracy: 0.7091\n",
            "Epoch 10/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5921 - accuracy: 0.7101 - val_loss: 0.5835 - val_accuracy: 0.7094\n",
            "Epoch 11/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5875 - accuracy: 0.7105 - val_loss: 0.5805 - val_accuracy: 0.7085\n",
            "Epoch 12/300\n",
            "1118/1118 [==============================] - 4s 3ms/step - loss: 0.5820 - accuracy: 0.7112 - val_loss: 0.5770 - val_accuracy: 0.7091\n",
            "Epoch 13/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5779 - accuracy: 0.7104 - val_loss: 0.5725 - val_accuracy: 0.7105\n",
            "Epoch 14/300\n",
            "1118/1118 [==============================] - 4s 3ms/step - loss: 0.5724 - accuracy: 0.7133 - val_loss: 0.5693 - val_accuracy: 0.7116\n",
            "Epoch 15/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5691 - accuracy: 0.7124 - val_loss: 0.5667 - val_accuracy: 0.7111\n",
            "Epoch 16/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5658 - accuracy: 0.7101 - val_loss: 0.5650 - val_accuracy: 0.7102\n",
            "Epoch 17/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5612 - accuracy: 0.7129 - val_loss: 0.5622 - val_accuracy: 0.7111\n",
            "Epoch 18/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5573 - accuracy: 0.7150 - val_loss: 0.5592 - val_accuracy: 0.7113\n",
            "Epoch 19/300\n",
            "1118/1118 [==============================] - 4s 3ms/step - loss: 0.5552 - accuracy: 0.7155 - val_loss: 0.5579 - val_accuracy: 0.7117\n",
            "Epoch 20/300\n",
            "1118/1118 [==============================] - 4s 3ms/step - loss: 0.5519 - accuracy: 0.7132 - val_loss: 0.5563 - val_accuracy: 0.7110\n",
            "Epoch 21/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5507 - accuracy: 0.7126 - val_loss: 0.5549 - val_accuracy: 0.7116\n",
            "Epoch 22/300\n",
            "1118/1118 [==============================] - 4s 3ms/step - loss: 0.5485 - accuracy: 0.7137 - val_loss: 0.5538 - val_accuracy: 0.7113\n",
            "Epoch 23/300\n",
            "1118/1118 [==============================] - 4s 3ms/step - loss: 0.5452 - accuracy: 0.7135 - val_loss: 0.5525 - val_accuracy: 0.7098\n",
            "Epoch 24/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5439 - accuracy: 0.7137 - val_loss: 0.5498 - val_accuracy: 0.7126\n",
            "Epoch 25/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5402 - accuracy: 0.7182 - val_loss: 0.5520 - val_accuracy: 0.7091\n",
            "Epoch 26/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5381 - accuracy: 0.7166 - val_loss: 0.5483 - val_accuracy: 0.7120\n",
            "Epoch 27/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5374 - accuracy: 0.7182 - val_loss: 0.5500 - val_accuracy: 0.7100\n",
            "Epoch 28/300\n",
            "1118/1118 [==============================] - 4s 3ms/step - loss: 0.5372 - accuracy: 0.7117 - val_loss: 0.5479 - val_accuracy: 0.7100\n",
            "Epoch 29/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5348 - accuracy: 0.7154 - val_loss: 0.5454 - val_accuracy: 0.7114\n",
            "Epoch 30/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.5325 - accuracy: 0.7158 - val_loss: 0.5443 - val_accuracy: 0.7114\n",
            "Epoch 31/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.5310 - accuracy: 0.7181 - val_loss: 0.5466 - val_accuracy: 0.7092\n",
            "Epoch 32/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5291 - accuracy: 0.7177 - val_loss: 0.5420 - val_accuracy: 0.7117\n",
            "Epoch 33/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5275 - accuracy: 0.7197 - val_loss: 0.5412 - val_accuracy: 0.7121\n",
            "Epoch 34/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5269 - accuracy: 0.7198 - val_loss: 0.5430 - val_accuracy: 0.7109\n",
            "Epoch 35/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5278 - accuracy: 0.7167 - val_loss: 0.5423 - val_accuracy: 0.7113\n",
            "Epoch 36/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5249 - accuracy: 0.7177 - val_loss: 0.5381 - val_accuracy: 0.7130\n",
            "Epoch 37/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5238 - accuracy: 0.7203 - val_loss: 0.5394 - val_accuracy: 0.7128\n",
            "Epoch 38/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5201 - accuracy: 0.7212 - val_loss: 0.5368 - val_accuracy: 0.7154\n",
            "Epoch 39/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5201 - accuracy: 0.7224 - val_loss: 0.5367 - val_accuracy: 0.7145\n",
            "Epoch 40/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5206 - accuracy: 0.7209 - val_loss: 0.5375 - val_accuracy: 0.7153\n",
            "Epoch 41/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5175 - accuracy: 0.7220 - val_loss: 0.5364 - val_accuracy: 0.7150\n",
            "Epoch 42/300\n",
            "1118/1118 [==============================] - 4s 3ms/step - loss: 0.5175 - accuracy: 0.7232 - val_loss: 0.5358 - val_accuracy: 0.7154\n",
            "Epoch 43/300\n",
            "1118/1118 [==============================] - 4s 3ms/step - loss: 0.5140 - accuracy: 0.7263 - val_loss: 0.5379 - val_accuracy: 0.7143\n",
            "Epoch 44/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5138 - accuracy: 0.7259 - val_loss: 0.5344 - val_accuracy: 0.7182\n",
            "Epoch 45/300\n",
            "1118/1118 [==============================] - 4s 3ms/step - loss: 0.5143 - accuracy: 0.7252 - val_loss: 0.5314 - val_accuracy: 0.7195\n",
            "Epoch 46/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5124 - accuracy: 0.7279 - val_loss: 0.5335 - val_accuracy: 0.7180\n",
            "Epoch 47/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5093 - accuracy: 0.7267 - val_loss: 0.5327 - val_accuracy: 0.7192\n",
            "Epoch 48/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5082 - accuracy: 0.7296 - val_loss: 0.5280 - val_accuracy: 0.7216\n",
            "Epoch 49/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5100 - accuracy: 0.7301 - val_loss: 0.5300 - val_accuracy: 0.7202\n",
            "Epoch 50/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5066 - accuracy: 0.7299 - val_loss: 0.5311 - val_accuracy: 0.7198\n",
            "Epoch 51/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5065 - accuracy: 0.7290 - val_loss: 0.5295 - val_accuracy: 0.7214\n",
            "Epoch 52/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5048 - accuracy: 0.7312 - val_loss: 0.5303 - val_accuracy: 0.7214\n",
            "Epoch 53/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5041 - accuracy: 0.7317 - val_loss: 0.5304 - val_accuracy: 0.7235\n",
            "Epoch 54/300\n",
            "1118/1118 [==============================] - 4s 3ms/step - loss: 0.5027 - accuracy: 0.7300 - val_loss: 0.5293 - val_accuracy: 0.7226\n",
            "Epoch 55/300\n",
            "1118/1118 [==============================] - 4s 3ms/step - loss: 0.5022 - accuracy: 0.7320 - val_loss: 0.5263 - val_accuracy: 0.7256\n",
            "Epoch 56/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5010 - accuracy: 0.7330 - val_loss: 0.5256 - val_accuracy: 0.7258\n",
            "Epoch 57/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5018 - accuracy: 0.7314 - val_loss: 0.5285 - val_accuracy: 0.7226\n",
            "Epoch 58/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.5001 - accuracy: 0.7317 - val_loss: 0.5250 - val_accuracy: 0.7246\n",
            "Epoch 59/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4998 - accuracy: 0.7329 - val_loss: 0.5264 - val_accuracy: 0.7252\n",
            "Epoch 60/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4976 - accuracy: 0.7371 - val_loss: 0.5280 - val_accuracy: 0.7232\n",
            "Epoch 61/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4965 - accuracy: 0.7358 - val_loss: 0.5263 - val_accuracy: 0.7245\n",
            "Epoch 62/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4979 - accuracy: 0.7367 - val_loss: 0.5250 - val_accuracy: 0.7267\n",
            "Epoch 63/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4935 - accuracy: 0.7383 - val_loss: 0.5242 - val_accuracy: 0.7270\n",
            "Epoch 64/300\n",
            "1118/1118 [==============================] - 4s 3ms/step - loss: 0.4955 - accuracy: 0.7363 - val_loss: 0.5243 - val_accuracy: 0.7265\n",
            "Epoch 65/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4929 - accuracy: 0.7389 - val_loss: 0.5241 - val_accuracy: 0.7276\n",
            "Epoch 66/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4929 - accuracy: 0.7382 - val_loss: 0.5223 - val_accuracy: 0.7286\n",
            "Epoch 67/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4912 - accuracy: 0.7420 - val_loss: 0.5254 - val_accuracy: 0.7268\n",
            "Epoch 68/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4911 - accuracy: 0.7394 - val_loss: 0.5224 - val_accuracy: 0.7285\n",
            "Epoch 69/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4917 - accuracy: 0.7400 - val_loss: 0.5252 - val_accuracy: 0.7260\n",
            "Epoch 70/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4913 - accuracy: 0.7390 - val_loss: 0.5256 - val_accuracy: 0.7254\n",
            "Epoch 71/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4900 - accuracy: 0.7404 - val_loss: 0.5245 - val_accuracy: 0.7267\n",
            "Epoch 72/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4888 - accuracy: 0.7414 - val_loss: 0.5243 - val_accuracy: 0.7255\n",
            "Epoch 73/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4861 - accuracy: 0.7418 - val_loss: 0.5200 - val_accuracy: 0.7280\n",
            "Epoch 74/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4897 - accuracy: 0.7422 - val_loss: 0.5233 - val_accuracy: 0.7256\n",
            "Epoch 75/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4843 - accuracy: 0.7431 - val_loss: 0.5222 - val_accuracy: 0.7267\n",
            "Epoch 76/300\n",
            "1118/1118 [==============================] - 6s 6ms/step - loss: 0.4855 - accuracy: 0.7410 - val_loss: 0.5210 - val_accuracy: 0.7268\n",
            "Epoch 77/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4838 - accuracy: 0.7439 - val_loss: 0.5219 - val_accuracy: 0.7273\n",
            "Epoch 78/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4831 - accuracy: 0.7442 - val_loss: 0.5220 - val_accuracy: 0.7270\n",
            "Epoch 79/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4843 - accuracy: 0.7424 - val_loss: 0.5249 - val_accuracy: 0.7239\n",
            "Epoch 80/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4811 - accuracy: 0.7425 - val_loss: 0.5197 - val_accuracy: 0.7286\n",
            "Epoch 81/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4806 - accuracy: 0.7456 - val_loss: 0.5153 - val_accuracy: 0.7322\n",
            "Epoch 82/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4817 - accuracy: 0.7457 - val_loss: 0.5204 - val_accuracy: 0.7270\n",
            "Epoch 83/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4789 - accuracy: 0.7467 - val_loss: 0.5191 - val_accuracy: 0.7282\n",
            "Epoch 84/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4775 - accuracy: 0.7464 - val_loss: 0.5172 - val_accuracy: 0.7306\n",
            "Epoch 85/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4790 - accuracy: 0.7472 - val_loss: 0.5219 - val_accuracy: 0.7257\n",
            "Epoch 86/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4788 - accuracy: 0.7450 - val_loss: 0.5215 - val_accuracy: 0.7264\n",
            "Epoch 87/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4765 - accuracy: 0.7461 - val_loss: 0.5167 - val_accuracy: 0.7320\n",
            "Epoch 88/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4776 - accuracy: 0.7453 - val_loss: 0.5187 - val_accuracy: 0.7306\n",
            "Epoch 89/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4762 - accuracy: 0.7478 - val_loss: 0.5170 - val_accuracy: 0.7301\n",
            "Epoch 90/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4734 - accuracy: 0.7492 - val_loss: 0.5194 - val_accuracy: 0.7293\n",
            "Epoch 91/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4745 - accuracy: 0.7485 - val_loss: 0.5189 - val_accuracy: 0.7294\n",
            "Epoch 92/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4722 - accuracy: 0.7506 - val_loss: 0.5169 - val_accuracy: 0.7309\n",
            "Epoch 93/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4751 - accuracy: 0.7466 - val_loss: 0.5159 - val_accuracy: 0.7299\n",
            "Epoch 94/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4743 - accuracy: 0.7473 - val_loss: 0.5166 - val_accuracy: 0.7294\n",
            "Epoch 95/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4740 - accuracy: 0.7486 - val_loss: 0.5173 - val_accuracy: 0.7296\n",
            "Epoch 96/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4718 - accuracy: 0.7489 - val_loss: 0.5192 - val_accuracy: 0.7293\n",
            "Epoch 97/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4698 - accuracy: 0.7504 - val_loss: 0.5183 - val_accuracy: 0.7298\n",
            "Epoch 98/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4700 - accuracy: 0.7509 - val_loss: 0.5159 - val_accuracy: 0.7315\n",
            "Epoch 99/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4679 - accuracy: 0.7542 - val_loss: 0.5158 - val_accuracy: 0.7317\n",
            "Epoch 100/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4686 - accuracy: 0.7550 - val_loss: 0.5200 - val_accuracy: 0.7276\n",
            "Epoch 101/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4673 - accuracy: 0.7518 - val_loss: 0.5168 - val_accuracy: 0.7306\n",
            "Epoch 102/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4673 - accuracy: 0.7517 - val_loss: 0.5123 - val_accuracy: 0.7355\n",
            "Epoch 103/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4678 - accuracy: 0.7531 - val_loss: 0.5168 - val_accuracy: 0.7321\n",
            "Epoch 104/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4662 - accuracy: 0.7526 - val_loss: 0.5169 - val_accuracy: 0.7321\n",
            "Epoch 105/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4661 - accuracy: 0.7536 - val_loss: 0.5170 - val_accuracy: 0.7312\n",
            "Epoch 106/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4647 - accuracy: 0.7511 - val_loss: 0.5138 - val_accuracy: 0.7334\n",
            "Epoch 107/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4648 - accuracy: 0.7537 - val_loss: 0.5145 - val_accuracy: 0.7329\n",
            "Epoch 108/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4643 - accuracy: 0.7565 - val_loss: 0.5178 - val_accuracy: 0.7314\n",
            "Epoch 109/300\n",
            "1118/1118 [==============================] - 6s 5ms/step - loss: 0.4643 - accuracy: 0.7549 - val_loss: 0.5133 - val_accuracy: 0.7355\n",
            "Epoch 110/300\n",
            "1118/1118 [==============================] - 7s 6ms/step - loss: 0.4649 - accuracy: 0.7542 - val_loss: 0.5160 - val_accuracy: 0.7337\n",
            "Epoch 111/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4609 - accuracy: 0.7574 - val_loss: 0.5155 - val_accuracy: 0.7310\n",
            "Epoch 112/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4607 - accuracy: 0.7558 - val_loss: 0.5180 - val_accuracy: 0.7301\n",
            "Epoch 113/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4617 - accuracy: 0.7544 - val_loss: 0.5164 - val_accuracy: 0.7313\n",
            "Epoch 114/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4612 - accuracy: 0.7538 - val_loss: 0.5193 - val_accuracy: 0.7281\n",
            "Epoch 115/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4597 - accuracy: 0.7553 - val_loss: 0.5161 - val_accuracy: 0.7323\n",
            "Epoch 116/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4612 - accuracy: 0.7557 - val_loss: 0.5177 - val_accuracy: 0.7305\n",
            "Epoch 117/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4579 - accuracy: 0.7567 - val_loss: 0.5151 - val_accuracy: 0.7329\n",
            "Epoch 118/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4565 - accuracy: 0.7589 - val_loss: 0.5191 - val_accuracy: 0.7293\n",
            "Epoch 119/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4579 - accuracy: 0.7571 - val_loss: 0.5160 - val_accuracy: 0.7322\n",
            "Epoch 120/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4578 - accuracy: 0.7569 - val_loss: 0.5167 - val_accuracy: 0.7305\n",
            "Epoch 121/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4565 - accuracy: 0.7561 - val_loss: 0.5117 - val_accuracy: 0.7350\n",
            "Epoch 122/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4572 - accuracy: 0.7604 - val_loss: 0.5202 - val_accuracy: 0.7290\n",
            "Epoch 123/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4573 - accuracy: 0.7556 - val_loss: 0.5118 - val_accuracy: 0.7362\n",
            "Epoch 124/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4557 - accuracy: 0.7564 - val_loss: 0.5149 - val_accuracy: 0.7319\n",
            "Epoch 125/300\n",
            "1118/1118 [==============================] - 4s 3ms/step - loss: 0.4533 - accuracy: 0.7588 - val_loss: 0.5153 - val_accuracy: 0.7318\n",
            "Epoch 126/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4576 - accuracy: 0.7583 - val_loss: 0.5205 - val_accuracy: 0.7294\n",
            "Epoch 127/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4514 - accuracy: 0.7605 - val_loss: 0.5105 - val_accuracy: 0.7370\n",
            "Epoch 128/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4546 - accuracy: 0.7578 - val_loss: 0.5164 - val_accuracy: 0.7322\n",
            "Epoch 129/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4519 - accuracy: 0.7584 - val_loss: 0.5142 - val_accuracy: 0.7337\n",
            "Epoch 130/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4536 - accuracy: 0.7574 - val_loss: 0.5142 - val_accuracy: 0.7329\n",
            "Epoch 131/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4532 - accuracy: 0.7603 - val_loss: 0.5168 - val_accuracy: 0.7314\n",
            "Epoch 132/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4525 - accuracy: 0.7603 - val_loss: 0.5199 - val_accuracy: 0.7290\n",
            "Epoch 133/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4499 - accuracy: 0.7592 - val_loss: 0.5180 - val_accuracy: 0.7306\n",
            "Epoch 134/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4509 - accuracy: 0.7593 - val_loss: 0.5170 - val_accuracy: 0.7320\n",
            "Epoch 135/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4508 - accuracy: 0.7601 - val_loss: 0.5151 - val_accuracy: 0.7327\n",
            "Epoch 136/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4495 - accuracy: 0.7603 - val_loss: 0.5138 - val_accuracy: 0.7336\n",
            "Epoch 137/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4506 - accuracy: 0.7592 - val_loss: 0.5170 - val_accuracy: 0.7314\n",
            "Epoch 138/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4489 - accuracy: 0.7608 - val_loss: 0.5133 - val_accuracy: 0.7328\n",
            "Epoch 139/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4497 - accuracy: 0.7615 - val_loss: 0.5172 - val_accuracy: 0.7312\n",
            "Epoch 140/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4467 - accuracy: 0.7601 - val_loss: 0.5147 - val_accuracy: 0.7320\n",
            "Epoch 141/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4507 - accuracy: 0.7582 - val_loss: 0.5151 - val_accuracy: 0.7315\n",
            "Epoch 142/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4494 - accuracy: 0.7590 - val_loss: 0.5127 - val_accuracy: 0.7338\n",
            "Epoch 143/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4490 - accuracy: 0.7609 - val_loss: 0.5133 - val_accuracy: 0.7339\n",
            "Epoch 144/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4495 - accuracy: 0.7601 - val_loss: 0.5151 - val_accuracy: 0.7317\n",
            "Epoch 145/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4462 - accuracy: 0.7627 - val_loss: 0.5155 - val_accuracy: 0.7322\n",
            "Epoch 146/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4470 - accuracy: 0.7606 - val_loss: 0.5138 - val_accuracy: 0.7336\n",
            "Epoch 147/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4481 - accuracy: 0.7603 - val_loss: 0.5157 - val_accuracy: 0.7312\n",
            "Epoch 148/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4454 - accuracy: 0.7616 - val_loss: 0.5105 - val_accuracy: 0.7358\n",
            "Epoch 149/300\n",
            "1118/1118 [==============================] - 5s 5ms/step - loss: 0.4454 - accuracy: 0.7634 - val_loss: 0.5135 - val_accuracy: 0.7337\n",
            "Epoch 150/300\n",
            "1118/1118 [==============================] - 6s 5ms/step - loss: 0.4444 - accuracy: 0.7614 - val_loss: 0.5126 - val_accuracy: 0.7347\n",
            "Epoch 151/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4427 - accuracy: 0.7634 - val_loss: 0.5114 - val_accuracy: 0.7366\n",
            "Epoch 152/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4463 - accuracy: 0.7629 - val_loss: 0.5185 - val_accuracy: 0.7312\n",
            "Epoch 153/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4454 - accuracy: 0.7606 - val_loss: 0.5168 - val_accuracy: 0.7312\n",
            "Epoch 154/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4452 - accuracy: 0.7627 - val_loss: 0.5182 - val_accuracy: 0.7305\n",
            "Epoch 155/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4443 - accuracy: 0.7641 - val_loss: 0.5201 - val_accuracy: 0.7303\n",
            "Epoch 156/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4431 - accuracy: 0.7627 - val_loss: 0.5175 - val_accuracy: 0.7331\n",
            "Epoch 157/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4429 - accuracy: 0.7648 - val_loss: 0.5165 - val_accuracy: 0.7329\n",
            "Epoch 158/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4452 - accuracy: 0.7609 - val_loss: 0.5147 - val_accuracy: 0.7348\n",
            "Epoch 159/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4434 - accuracy: 0.7621 - val_loss: 0.5136 - val_accuracy: 0.7337\n",
            "Epoch 160/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4442 - accuracy: 0.7621 - val_loss: 0.5145 - val_accuracy: 0.7337\n",
            "Epoch 161/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4416 - accuracy: 0.7653 - val_loss: 0.5178 - val_accuracy: 0.7309\n",
            "Epoch 162/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4432 - accuracy: 0.7612 - val_loss: 0.5190 - val_accuracy: 0.7305\n",
            "Epoch 163/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4430 - accuracy: 0.7612 - val_loss: 0.5108 - val_accuracy: 0.7365\n",
            "Epoch 164/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4431 - accuracy: 0.7638 - val_loss: 0.5109 - val_accuracy: 0.7361\n",
            "Epoch 165/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4418 - accuracy: 0.7636 - val_loss: 0.5150 - val_accuracy: 0.7327\n",
            "Epoch 166/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4401 - accuracy: 0.7633 - val_loss: 0.5110 - val_accuracy: 0.7366\n",
            "Epoch 167/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4400 - accuracy: 0.7634 - val_loss: 0.5136 - val_accuracy: 0.7351\n",
            "Epoch 168/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4415 - accuracy: 0.7643 - val_loss: 0.5142 - val_accuracy: 0.7348\n",
            "Epoch 169/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4408 - accuracy: 0.7626 - val_loss: 0.5157 - val_accuracy: 0.7348\n",
            "Epoch 170/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4404 - accuracy: 0.7646 - val_loss: 0.5160 - val_accuracy: 0.7327\n",
            "Epoch 171/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4397 - accuracy: 0.7633 - val_loss: 0.5133 - val_accuracy: 0.7348\n",
            "Epoch 172/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4389 - accuracy: 0.7655 - val_loss: 0.5197 - val_accuracy: 0.7306\n",
            "Epoch 173/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4371 - accuracy: 0.7634 - val_loss: 0.5124 - val_accuracy: 0.7353\n",
            "Epoch 174/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4382 - accuracy: 0.7653 - val_loss: 0.5126 - val_accuracy: 0.7346\n",
            "Epoch 175/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4386 - accuracy: 0.7635 - val_loss: 0.5171 - val_accuracy: 0.7321\n",
            "Epoch 176/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4354 - accuracy: 0.7659 - val_loss: 0.5188 - val_accuracy: 0.7312\n",
            "Epoch 177/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4376 - accuracy: 0.7653 - val_loss: 0.5138 - val_accuracy: 0.7340\n",
            "Epoch 178/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4356 - accuracy: 0.7671 - val_loss: 0.5137 - val_accuracy: 0.7343\n",
            "Epoch 179/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4366 - accuracy: 0.7670 - val_loss: 0.5173 - val_accuracy: 0.7334\n",
            "Epoch 180/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4362 - accuracy: 0.7678 - val_loss: 0.5168 - val_accuracy: 0.7323\n",
            "Epoch 181/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4367 - accuracy: 0.7636 - val_loss: 0.5121 - val_accuracy: 0.7356\n",
            "Epoch 182/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4355 - accuracy: 0.7685 - val_loss: 0.5129 - val_accuracy: 0.7341\n",
            "Epoch 183/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4352 - accuracy: 0.7677 - val_loss: 0.5148 - val_accuracy: 0.7338\n",
            "Epoch 184/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4357 - accuracy: 0.7658 - val_loss: 0.5146 - val_accuracy: 0.7337\n",
            "Epoch 185/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4340 - accuracy: 0.7680 - val_loss: 0.5122 - val_accuracy: 0.7356\n",
            "Epoch 186/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4348 - accuracy: 0.7668 - val_loss: 0.5100 - val_accuracy: 0.7360\n",
            "Epoch 187/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4321 - accuracy: 0.7708 - val_loss: 0.5137 - val_accuracy: 0.7351\n",
            "Epoch 188/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4329 - accuracy: 0.7698 - val_loss: 0.5156 - val_accuracy: 0.7342\n",
            "Epoch 189/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4338 - accuracy: 0.7675 - val_loss: 0.5176 - val_accuracy: 0.7339\n",
            "Epoch 190/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4337 - accuracy: 0.7657 - val_loss: 0.5127 - val_accuracy: 0.7372\n",
            "Epoch 191/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4321 - accuracy: 0.7696 - val_loss: 0.5168 - val_accuracy: 0.7355\n",
            "Epoch 192/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4348 - accuracy: 0.7662 - val_loss: 0.5172 - val_accuracy: 0.7343\n",
            "Epoch 193/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4334 - accuracy: 0.7692 - val_loss: 0.5198 - val_accuracy: 0.7337\n",
            "Epoch 194/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4346 - accuracy: 0.7662 - val_loss: 0.5158 - val_accuracy: 0.7340\n",
            "Epoch 195/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4334 - accuracy: 0.7688 - val_loss: 0.5158 - val_accuracy: 0.7348\n",
            "Epoch 196/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4332 - accuracy: 0.7682 - val_loss: 0.5137 - val_accuracy: 0.7355\n",
            "Epoch 197/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4319 - accuracy: 0.7692 - val_loss: 0.5204 - val_accuracy: 0.7308\n",
            "Epoch 198/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4290 - accuracy: 0.7699 - val_loss: 0.5164 - val_accuracy: 0.7346\n",
            "Epoch 199/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4336 - accuracy: 0.7675 - val_loss: 0.5147 - val_accuracy: 0.7359\n",
            "Epoch 200/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4309 - accuracy: 0.7689 - val_loss: 0.5126 - val_accuracy: 0.7372\n",
            "Epoch 201/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4313 - accuracy: 0.7696 - val_loss: 0.5151 - val_accuracy: 0.7356\n",
            "Epoch 202/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4329 - accuracy: 0.7684 - val_loss: 0.5163 - val_accuracy: 0.7347\n",
            "Epoch 203/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4306 - accuracy: 0.7691 - val_loss: 0.5142 - val_accuracy: 0.7366\n",
            "Epoch 204/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4326 - accuracy: 0.7656 - val_loss: 0.5143 - val_accuracy: 0.7372\n",
            "Epoch 205/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4331 - accuracy: 0.7676 - val_loss: 0.5171 - val_accuracy: 0.7351\n",
            "Epoch 206/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4315 - accuracy: 0.7689 - val_loss: 0.5150 - val_accuracy: 0.7371\n",
            "Epoch 207/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4345 - accuracy: 0.7663 - val_loss: 0.5197 - val_accuracy: 0.7339\n",
            "Epoch 208/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4318 - accuracy: 0.7675 - val_loss: 0.5169 - val_accuracy: 0.7358\n",
            "Epoch 209/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4320 - accuracy: 0.7681 - val_loss: 0.5182 - val_accuracy: 0.7352\n",
            "Epoch 210/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4299 - accuracy: 0.7700 - val_loss: 0.5182 - val_accuracy: 0.7359\n",
            "Epoch 211/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4308 - accuracy: 0.7695 - val_loss: 0.5157 - val_accuracy: 0.7361\n",
            "Epoch 212/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4314 - accuracy: 0.7680 - val_loss: 0.5188 - val_accuracy: 0.7339\n",
            "Epoch 213/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4282 - accuracy: 0.7688 - val_loss: 0.5136 - val_accuracy: 0.7377\n",
            "Epoch 214/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4288 - accuracy: 0.7727 - val_loss: 0.5171 - val_accuracy: 0.7374\n",
            "Epoch 215/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4286 - accuracy: 0.7719 - val_loss: 0.5236 - val_accuracy: 0.7330\n",
            "Epoch 216/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4268 - accuracy: 0.7699 - val_loss: 0.5190 - val_accuracy: 0.7362\n",
            "Epoch 217/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4288 - accuracy: 0.7721 - val_loss: 0.5224 - val_accuracy: 0.7334\n",
            "Epoch 218/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4302 - accuracy: 0.7671 - val_loss: 0.5180 - val_accuracy: 0.7367\n",
            "Epoch 219/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4290 - accuracy: 0.7687 - val_loss: 0.5187 - val_accuracy: 0.7356\n",
            "Epoch 220/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4266 - accuracy: 0.7699 - val_loss: 0.5199 - val_accuracy: 0.7355\n",
            "Epoch 221/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.4297 - accuracy: 0.7701 - val_loss: 0.5203 - val_accuracy: 0.7350\n",
            "Epoch 222/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4276 - accuracy: 0.7717 - val_loss: 0.5224 - val_accuracy: 0.7332\n",
            "Epoch 223/300\n",
            "1118/1118 [==============================] - 7s 6ms/step - loss: 0.4301 - accuracy: 0.7676 - val_loss: 0.5177 - val_accuracy: 0.7364\n",
            "Epoch 224/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.4266 - accuracy: 0.7694 - val_loss: 0.5145 - val_accuracy: 0.7391\n",
            "Epoch 225/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4281 - accuracy: 0.7710 - val_loss: 0.5169 - val_accuracy: 0.7368\n",
            "Epoch 226/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4283 - accuracy: 0.7707 - val_loss: 0.5202 - val_accuracy: 0.7356\n",
            "Epoch 227/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4272 - accuracy: 0.7716 - val_loss: 0.5155 - val_accuracy: 0.7385\n",
            "Epoch 228/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4258 - accuracy: 0.7732 - val_loss: 0.5173 - val_accuracy: 0.7380\n",
            "Epoch 229/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4293 - accuracy: 0.7703 - val_loss: 0.5167 - val_accuracy: 0.7379\n",
            "Epoch 230/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4266 - accuracy: 0.7705 - val_loss: 0.5163 - val_accuracy: 0.7379\n",
            "Epoch 231/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4246 - accuracy: 0.7723 - val_loss: 0.5137 - val_accuracy: 0.7400\n",
            "Epoch 232/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4275 - accuracy: 0.7714 - val_loss: 0.5163 - val_accuracy: 0.7377\n",
            "Epoch 233/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4254 - accuracy: 0.7715 - val_loss: 0.5144 - val_accuracy: 0.7378\n",
            "Epoch 234/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4254 - accuracy: 0.7755 - val_loss: 0.5206 - val_accuracy: 0.7355\n",
            "Epoch 235/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4254 - accuracy: 0.7719 - val_loss: 0.5157 - val_accuracy: 0.7389\n",
            "Epoch 236/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4259 - accuracy: 0.7720 - val_loss: 0.5169 - val_accuracy: 0.7383\n",
            "Epoch 237/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4246 - accuracy: 0.7739 - val_loss: 0.5148 - val_accuracy: 0.7390\n",
            "Epoch 238/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4259 - accuracy: 0.7719 - val_loss: 0.5167 - val_accuracy: 0.7385\n",
            "Epoch 239/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4253 - accuracy: 0.7734 - val_loss: 0.5184 - val_accuracy: 0.7374\n",
            "Epoch 240/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4286 - accuracy: 0.7682 - val_loss: 0.5168 - val_accuracy: 0.7375\n",
            "Epoch 241/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4257 - accuracy: 0.7735 - val_loss: 0.5188 - val_accuracy: 0.7370\n",
            "Epoch 242/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4247 - accuracy: 0.7729 - val_loss: 0.5219 - val_accuracy: 0.7357\n",
            "Epoch 243/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4262 - accuracy: 0.7704 - val_loss: 0.5203 - val_accuracy: 0.7372\n",
            "Epoch 244/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.4236 - accuracy: 0.7718 - val_loss: 0.5209 - val_accuracy: 0.7359\n",
            "Epoch 245/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4234 - accuracy: 0.7713 - val_loss: 0.5174 - val_accuracy: 0.7384\n",
            "Epoch 246/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4247 - accuracy: 0.7745 - val_loss: 0.5258 - val_accuracy: 0.7340\n",
            "Epoch 247/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4233 - accuracy: 0.7721 - val_loss: 0.5178 - val_accuracy: 0.7394\n",
            "Epoch 248/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4235 - accuracy: 0.7731 - val_loss: 0.5201 - val_accuracy: 0.7358\n",
            "Epoch 249/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4244 - accuracy: 0.7722 - val_loss: 0.5191 - val_accuracy: 0.7362\n",
            "Epoch 250/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4240 - accuracy: 0.7707 - val_loss: 0.5179 - val_accuracy: 0.7374\n",
            "Epoch 251/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4235 - accuracy: 0.7742 - val_loss: 0.5186 - val_accuracy: 0.7372\n",
            "Epoch 252/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4266 - accuracy: 0.7713 - val_loss: 0.5211 - val_accuracy: 0.7377\n",
            "Epoch 253/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4226 - accuracy: 0.7755 - val_loss: 0.5225 - val_accuracy: 0.7368\n",
            "Epoch 254/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4225 - accuracy: 0.7747 - val_loss: 0.5217 - val_accuracy: 0.7366\n",
            "Epoch 255/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4238 - accuracy: 0.7716 - val_loss: 0.5211 - val_accuracy: 0.7364\n",
            "Epoch 256/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4211 - accuracy: 0.7744 - val_loss: 0.5212 - val_accuracy: 0.7351\n",
            "Epoch 257/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.4242 - accuracy: 0.7719 - val_loss: 0.5246 - val_accuracy: 0.7343\n",
            "Epoch 258/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4226 - accuracy: 0.7741 - val_loss: 0.5178 - val_accuracy: 0.7386\n",
            "Epoch 259/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.4205 - accuracy: 0.7732 - val_loss: 0.5180 - val_accuracy: 0.7391\n",
            "Epoch 260/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4212 - accuracy: 0.7750 - val_loss: 0.5198 - val_accuracy: 0.7369\n",
            "Epoch 261/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4204 - accuracy: 0.7743 - val_loss: 0.5158 - val_accuracy: 0.7399\n",
            "Epoch 262/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4226 - accuracy: 0.7725 - val_loss: 0.5194 - val_accuracy: 0.7378\n",
            "Epoch 263/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4206 - accuracy: 0.7743 - val_loss: 0.5225 - val_accuracy: 0.7364\n",
            "Epoch 264/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4217 - accuracy: 0.7740 - val_loss: 0.5226 - val_accuracy: 0.7368\n",
            "Epoch 265/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4232 - accuracy: 0.7726 - val_loss: 0.5221 - val_accuracy: 0.7364\n",
            "Epoch 266/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.4237 - accuracy: 0.7721 - val_loss: 0.5199 - val_accuracy: 0.7385\n",
            "Epoch 267/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4229 - accuracy: 0.7746 - val_loss: 0.5203 - val_accuracy: 0.7379\n",
            "Epoch 268/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4222 - accuracy: 0.7744 - val_loss: 0.5215 - val_accuracy: 0.7368\n",
            "Epoch 269/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4200 - accuracy: 0.7742 - val_loss: 0.5150 - val_accuracy: 0.7415\n",
            "Epoch 270/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4202 - accuracy: 0.7767 - val_loss: 0.5235 - val_accuracy: 0.7356\n",
            "Epoch 271/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.4225 - accuracy: 0.7721 - val_loss: 0.5186 - val_accuracy: 0.7384\n",
            "Epoch 272/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4239 - accuracy: 0.7735 - val_loss: 0.5255 - val_accuracy: 0.7342\n",
            "Epoch 273/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4202 - accuracy: 0.7757 - val_loss: 0.5249 - val_accuracy: 0.7346\n",
            "Epoch 274/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.4214 - accuracy: 0.7736 - val_loss: 0.5183 - val_accuracy: 0.7388\n",
            "Epoch 275/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4206 - accuracy: 0.7745 - val_loss: 0.5231 - val_accuracy: 0.7361\n",
            "Epoch 276/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4202 - accuracy: 0.7779 - val_loss: 0.5288 - val_accuracy: 0.7337\n",
            "Epoch 277/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.4214 - accuracy: 0.7748 - val_loss: 0.5248 - val_accuracy: 0.7352\n",
            "Epoch 278/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.4192 - accuracy: 0.7760 - val_loss: 0.5257 - val_accuracy: 0.7358\n",
            "Epoch 279/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.4202 - accuracy: 0.7746 - val_loss: 0.5194 - val_accuracy: 0.7385\n",
            "Epoch 280/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4202 - accuracy: 0.7766 - val_loss: 0.5202 - val_accuracy: 0.7384\n",
            "Epoch 281/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.4241 - accuracy: 0.7710 - val_loss: 0.5192 - val_accuracy: 0.7375\n",
            "Epoch 282/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.4224 - accuracy: 0.7740 - val_loss: 0.5248 - val_accuracy: 0.7349\n",
            "Epoch 283/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4180 - accuracy: 0.7786 - val_loss: 0.5253 - val_accuracy: 0.7352\n",
            "Epoch 284/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.4209 - accuracy: 0.7748 - val_loss: 0.5229 - val_accuracy: 0.7378\n",
            "Epoch 285/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4189 - accuracy: 0.7763 - val_loss: 0.5189 - val_accuracy: 0.7385\n",
            "Epoch 286/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.4189 - accuracy: 0.7774 - val_loss: 0.5248 - val_accuracy: 0.7358\n",
            "Epoch 287/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.4223 - accuracy: 0.7751 - val_loss: 0.5206 - val_accuracy: 0.7386\n",
            "Epoch 288/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4204 - accuracy: 0.7757 - val_loss: 0.5206 - val_accuracy: 0.7391\n",
            "Epoch 289/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.4212 - accuracy: 0.7738 - val_loss: 0.5206 - val_accuracy: 0.7374\n",
            "Epoch 290/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.4199 - accuracy: 0.7762 - val_loss: 0.5221 - val_accuracy: 0.7372\n",
            "Epoch 291/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.4199 - accuracy: 0.7765 - val_loss: 0.5233 - val_accuracy: 0.7372\n",
            "Epoch 292/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.4181 - accuracy: 0.7765 - val_loss: 0.5215 - val_accuracy: 0.7377\n",
            "Epoch 293/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.4165 - accuracy: 0.7786 - val_loss: 0.5257 - val_accuracy: 0.7359\n",
            "Epoch 294/300\n",
            "1118/1118 [==============================] - 7s 6ms/step - loss: 0.4188 - accuracy: 0.7760 - val_loss: 0.5245 - val_accuracy: 0.7368\n",
            "Epoch 295/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.4172 - accuracy: 0.7779 - val_loss: 0.5225 - val_accuracy: 0.7380\n",
            "Epoch 296/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.4174 - accuracy: 0.7785 - val_loss: 0.5240 - val_accuracy: 0.7379\n",
            "Epoch 297/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.4187 - accuracy: 0.7763 - val_loss: 0.5181 - val_accuracy: 0.7409\n",
            "Epoch 298/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.4171 - accuracy: 0.7788 - val_loss: 0.5261 - val_accuracy: 0.7368\n",
            "Epoch 299/300\n",
            "1118/1118 [==============================] - 5s 4ms/step - loss: 0.4204 - accuracy: 0.7743 - val_loss: 0.5225 - val_accuracy: 0.7383\n",
            "Epoch 300/300\n",
            "1118/1118 [==============================] - 4s 4ms/step - loss: 0.4196 - accuracy: 0.7746 - val_loss: 0.5216 - val_accuracy: 0.7386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.predict(X_test)\n",
        "print(result)\n",
        "\n",
        "pred_dicts = list(model.predict(X_test))\n",
        "probs = pd.Series([float(pred) for pred in pred_dicts])\n",
        "\n",
        "print(probs)\n",
        "probs.plot(kind='hist', bins=20, title='predicted probabilities')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "Xlw4zRnZRB2q",
        "outputId": "9ab59a20-f6e1-42a8-cd84-12c18858d741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "280/280 [==============================] - 0s 2ms/step\n",
            "[[0.04552522]\n",
            " [0.67026216]\n",
            " [0.7415993 ]\n",
            " ...\n",
            " [0.8422796 ]\n",
            " [0.29321635]\n",
            " [0.8698072 ]]\n",
            "280/280 [==============================] - 0s 2ms/step\n",
            "0       0.045525\n",
            "1       0.670262\n",
            "2       0.741599\n",
            "3       0.462079\n",
            "4       0.271783\n",
            "          ...   \n",
            "8935    0.179376\n",
            "8936    0.245862\n",
            "8937    0.842280\n",
            "8938    0.293216\n",
            "8939    0.869807\n",
            "Length: 8940, dtype: float64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f24a50dc790>"
            ]
          },
          "metadata": {},
          "execution_count": 162
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.lib.function_base import append\n",
        "x = []\n",
        "y = []\n",
        "tot = []\n",
        "\n",
        "for i in probs:\n",
        "  if i > 0.5:\n",
        "    x.append(i)\n",
        "    tot.append(1)\n",
        "  else:\n",
        "    y.append(i)\n",
        "    tot.append(0)\n",
        "    \n",
        "\n",
        "print(len(x), len(y))\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import metrics\n",
        "\n",
        "print(classification_report(y_test, tot))\n",
        "print(metrics.confusion_matrix(y_test, tot))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4_rx2KJVNy-",
        "outputId": "a3bac6e0-b084-4b79-edcb-0243773e09db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2793 6147\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.75      0.83      7608\n",
            "           1       0.32      0.67      0.43      1332\n",
            "\n",
            "    accuracy                           0.74      8940\n",
            "   macro avg       0.62      0.71      0.63      8940\n",
            "weighted avg       0.84      0.74      0.77      8940\n",
            "\n",
            "[[5709 1899]\n",
            " [ 438  894]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "colors_BA = ['#075AAA','#EB2226', '#EFE9E5','#B9CFED']"
      ],
      "metadata": {
        "id": "dn6pu8UxYKVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss(history, label, n):\n",
        "  # Use a log scale on y-axis to show the wide range of values.\n",
        "  plt.semilogy(history.epoch, history.history['loss'],\n",
        "               color='#075AAA', label='Train ' + label)\n",
        "  plt.semilogy(history.epoch, history.history['val_loss'],\n",
        "               color='#EB2226', label='Val ' + label,\n",
        "               linestyle=\"--\")\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "def plot_acc(history, label, n):\n",
        "  # Use a log scale on y-axis to show the wide range of values.\n",
        "  plt.semilogy(history.epoch, history.history['accuracy'],\n",
        "               color='#075AAA', label='Train ' + label)\n",
        "  plt.semilogy(history.epoch, history.history['val_accuracy'],\n",
        "               color='#EB2226', label='Val ' + label,\n",
        "               linestyle=\"--\")\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('accuracy')\n"
      ],
      "metadata": {
        "id": "YIgYkMPWv-It"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss(history, \"Zero Bias\", 0)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "8N4RlU04wG7I",
        "outputId": "5d05326f-73a5-4d11-af7e-93b69f3eab4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_acc(history, \"acc\", 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "dC0mCQbeQtel",
        "outputId": "749ff6ab-1641-4e13-8405-4dbc8a08a90c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(model=create_larger, epochs=1, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
        "results = cross_val_score(pipeline, X_train, y_train, cv=kfold)\n",
        "print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "metadata": {
        "id": "xmVMbm1QuDAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    '''The function creates a Perceptron using Keras'''\n",
        "    model = Sequential()\n",
        "    model.add(Dense(10, input_dim=918, activation='sigmoid'))\n",
        "    model.add(Dense(6, activation='sigmoid'))\n",
        "    model.add(Dense(1, activation='softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "estimator = create_model()\n",
        "estimator.compile(optimizer = opt, metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()], loss='binary_crossentropy')\n",
        "model1 = estimator.fit(X_train,y_train, batch_size=10 , epochs=20, verbose=1, shuffle=True, validation_data=(X_test, y_test), class_weight = class_weights)"
      ],
      "metadata": {
        "id": "_GdskaizQteI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.predict(X_test)\n",
        "print(result)\n",
        "\n",
        "pred_dicts = list(model.predict(X_test))\n",
        "probs = pd.Series([float(pred) for pred in pred_dicts])\n",
        "\n",
        "print(probs)\n",
        "probs.plot(kind='hist', bins=20, title='predicted probabilities')"
      ],
      "metadata": {
        "id": "zMCSpy-rU2Z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.constraints import MaxNorm\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "classifier = Sequential()\n",
        "# Defining the Input layer and FIRST hidden layer,both are same!\n",
        "# relu means Rectifier linear unit function\n",
        "classifier.add(Dropout(0.2, input_shape=(911,)))\n",
        "\n",
        "classifier.add(Dense(units=10, kernel_initializer='uniform', activation='softmax', kernel_constraint=MaxNorm(3)))\n",
        "\n",
        "#Defining the SECOND hidden layer, here we have not defined input because it is\n",
        "# second layer and it will get input as the output of first hidden layer\n",
        "classifier.add(Dense(units=6, kernel_initializer='uniform', activation='softmax', kernel_constraint=MaxNorm(3)))\n",
        "\n",
        "# Defining the Output layer\n",
        "# sigmoid means sigmoid activation function\n",
        "# for Multiclass classification the activation ='softmax'\n",
        "# And output_dim will be equal to the number of factor levels\n",
        "classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "\n",
        "# Optimizer== the algorithm of SGG to keep updating weights\n",
        "# loss== the loss function to measu1re the accuracy\n",
        "# metrics== the way we will compare the accuracy after each step of SGD\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001, decay=1e-6)\n",
        "classifier.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# fitting the Neural Network on the training data\n",
        "survivalANN_Model=classifier.fit(X_train,y_train, batch_size=10 , epochs=100, verbose=1, shuffle=True, class_weight = class_weights)\n"
      ],
      "metadata": {
        "id": "t5pBw_H7qScL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "322f770d-6979-4d47-c654-0e09226514ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3576/3576 [==============================] - 10s 2ms/step - loss: 0.6930 - accuracy: 0.1510\n",
            "Epoch 2/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.6908 - accuracy: 0.6923\n",
            "Epoch 3/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.6818 - accuracy: 0.6833\n",
            "Epoch 4/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.6646 - accuracy: 0.7095\n",
            "Epoch 5/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.6443 - accuracy: 0.7021\n",
            "Epoch 6/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.6245 - accuracy: 0.7018\n",
            "Epoch 7/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.6077 - accuracy: 0.6965\n",
            "Epoch 8/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5929 - accuracy: 0.7022\n",
            "Epoch 9/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5835 - accuracy: 0.6995\n",
            "Epoch 10/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5786 - accuracy: 0.6984\n",
            "Epoch 11/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5724 - accuracy: 0.6978\n",
            "Epoch 12/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5673 - accuracy: 0.7022\n",
            "Epoch 13/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5655 - accuracy: 0.6960\n",
            "Epoch 14/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5632 - accuracy: 0.6984\n",
            "Epoch 15/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5612 - accuracy: 0.6983\n",
            "Epoch 16/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5607 - accuracy: 0.7000\n",
            "Epoch 17/100\n",
            "3576/3576 [==============================] - 9s 3ms/step - loss: 0.5568 - accuracy: 0.6988\n",
            "Epoch 18/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5566 - accuracy: 0.6972\n",
            "Epoch 19/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5550 - accuracy: 0.7015\n",
            "Epoch 20/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5523 - accuracy: 0.6996\n",
            "Epoch 21/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5531 - accuracy: 0.7026\n",
            "Epoch 22/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5518 - accuracy: 0.6977\n",
            "Epoch 23/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5507 - accuracy: 0.7018\n",
            "Epoch 24/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5515 - accuracy: 0.6974\n",
            "Epoch 25/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5518 - accuracy: 0.6925\n",
            "Epoch 26/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5480 - accuracy: 0.6978\n",
            "Epoch 27/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5479 - accuracy: 0.7012\n",
            "Epoch 28/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5490 - accuracy: 0.6988\n",
            "Epoch 29/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5504 - accuracy: 0.6966\n",
            "Epoch 30/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5491 - accuracy: 0.6996\n",
            "Epoch 31/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5460 - accuracy: 0.6987\n",
            "Epoch 32/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5475 - accuracy: 0.6960\n",
            "Epoch 33/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5458 - accuracy: 0.6984\n",
            "Epoch 34/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5447 - accuracy: 0.6966\n",
            "Epoch 35/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5471 - accuracy: 0.6975\n",
            "Epoch 36/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5438 - accuracy: 0.6998\n",
            "Epoch 37/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5478 - accuracy: 0.6950\n",
            "Epoch 38/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5466 - accuracy: 0.7004\n",
            "Epoch 39/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5428 - accuracy: 0.6952\n",
            "Epoch 40/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5437 - accuracy: 0.6976\n",
            "Epoch 41/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5443 - accuracy: 0.6994\n",
            "Epoch 42/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5441 - accuracy: 0.6971\n",
            "Epoch 43/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5449 - accuracy: 0.6990\n",
            "Epoch 44/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5440 - accuracy: 0.6998\n",
            "Epoch 45/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5437 - accuracy: 0.6963\n",
            "Epoch 46/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5429 - accuracy: 0.7037\n",
            "Epoch 47/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5429 - accuracy: 0.7015\n",
            "Epoch 48/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5423 - accuracy: 0.6996\n",
            "Epoch 49/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5407 - accuracy: 0.7036\n",
            "Epoch 50/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5423 - accuracy: 0.7015\n",
            "Epoch 51/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5398 - accuracy: 0.7036\n",
            "Epoch 52/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5418 - accuracy: 0.7046\n",
            "Epoch 53/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5408 - accuracy: 0.7045\n",
            "Epoch 54/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5407 - accuracy: 0.7024\n",
            "Epoch 55/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5404 - accuracy: 0.7092\n",
            "Epoch 56/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5410 - accuracy: 0.7054\n",
            "Epoch 57/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5406 - accuracy: 0.7089\n",
            "Epoch 58/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5387 - accuracy: 0.7106\n",
            "Epoch 59/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5386 - accuracy: 0.7095\n",
            "Epoch 60/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5370 - accuracy: 0.7108\n",
            "Epoch 61/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5357 - accuracy: 0.7135\n",
            "Epoch 62/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5377 - accuracy: 0.7140\n",
            "Epoch 63/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5347 - accuracy: 0.7137\n",
            "Epoch 64/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5383 - accuracy: 0.7128\n",
            "Epoch 65/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5385 - accuracy: 0.7136\n",
            "Epoch 66/100\n",
            "3576/3576 [==============================] - 9s 3ms/step - loss: 0.5371 - accuracy: 0.7091\n",
            "Epoch 67/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5388 - accuracy: 0.7124\n",
            "Epoch 68/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5406 - accuracy: 0.7093\n",
            "Epoch 69/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5383 - accuracy: 0.7142\n",
            "Epoch 70/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5350 - accuracy: 0.7126\n",
            "Epoch 71/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5384 - accuracy: 0.7135\n",
            "Epoch 72/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5362 - accuracy: 0.7135\n",
            "Epoch 73/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5355 - accuracy: 0.7125\n",
            "Epoch 74/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5348 - accuracy: 0.7135\n",
            "Epoch 75/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5343 - accuracy: 0.7147\n",
            "Epoch 76/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5383 - accuracy: 0.7112\n",
            "Epoch 77/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5350 - accuracy: 0.7144\n",
            "Epoch 78/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5337 - accuracy: 0.7164\n",
            "Epoch 79/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5321 - accuracy: 0.7164\n",
            "Epoch 80/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5362 - accuracy: 0.7116\n",
            "Epoch 81/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5348 - accuracy: 0.7145\n",
            "Epoch 82/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5351 - accuracy: 0.7114\n",
            "Epoch 83/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5370 - accuracy: 0.7137\n",
            "Epoch 84/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5357 - accuracy: 0.7101\n",
            "Epoch 85/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5347 - accuracy: 0.7136\n",
            "Epoch 86/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5337 - accuracy: 0.7122\n",
            "Epoch 87/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5328 - accuracy: 0.7121\n",
            "Epoch 88/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5324 - accuracy: 0.7175\n",
            "Epoch 89/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5327 - accuracy: 0.7131\n",
            "Epoch 90/100\n",
            "3576/3576 [==============================] - 9s 3ms/step - loss: 0.5329 - accuracy: 0.7140\n",
            "Epoch 91/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5351 - accuracy: 0.7118\n",
            "Epoch 92/100\n",
            "3576/3576 [==============================] - 8s 2ms/step - loss: 0.5338 - accuracy: 0.7092\n",
            "Epoch 93/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5327 - accuracy: 0.7108\n",
            "Epoch 94/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5347 - accuracy: 0.7132\n",
            "Epoch 95/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5330 - accuracy: 0.7122\n",
            "Epoch 96/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5326 - accuracy: 0.7119\n",
            "Epoch 97/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5318 - accuracy: 0.7121\n",
            "Epoch 98/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5301 - accuracy: 0.7140\n",
            "Epoch 99/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5304 - accuracy: 0.7124\n",
            "Epoch 100/100\n",
            "3576/3576 [==============================] - 9s 2ms/step - loss: 0.5308 - accuracy: 0.7160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "PredictorScaler=StandardScaler()\n",
        " \n",
        "# Storing the fit object for later reference\n",
        "PredictorScalerFit=PredictorScaler.fit(X)\n",
        " \n",
        "# Generating the standardized values of X and y\n",
        "\n",
        "Predictions=classifier.predict(X_test)\n",
        " \n",
        "# Scaling the test data back to original scale\n",
        "Test_Data=PredictorScalerFit.inverse_transform(X_test)\n",
        " \n",
        "# Generating a data frame for analyzing the test data\n",
        "TestingData=pd.DataFrame(data=Test_Data, columns=Predictors)\n",
        "TestingData['booking_complete']=y_test\n",
        "TestingData['PredictedbookProb']=Predictions\n",
        " \n",
        "# Defining the probability threshold\n",
        "def probThreshold(inpProb):\n",
        "    if inpProb > 0.5:\n",
        "        return(1)\n",
        "    else:\n",
        "        return(0)\n",
        " \n",
        "# Generating predictions on the testing data by applying probability threshold\n",
        "TestingData['Predictedbook']=TestingData['PredictedbookProb'].apply(probThreshold)\n",
        "print(TestingData.head())\n",
        " \n",
        "###############################################\n",
        "from sklearn import metrics\n",
        "print('\\n######### Testing Accuracy Results #########')\n",
        "print(metrics.classification_report(TestingData['booking_complete'], TestingData['Predictedbook']))\n",
        "print(metrics.confusion_matrix(TestingData['booking_complete'], TestingData['Predictedbook']))\n",
        "print((TestingData['booking_complete'], TestingData['Predictedbook']))"
      ],
      "metadata": {
        "id": "eHfA87wXrIqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e3724e7-d129-41ec-d8d8-84378cc912ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "280/280 [==============================] - 0s 1ms/step\n",
            "   num_passengers  sales_channel  trip_type  purchase_lead  length_of_stay  \\\n",
            "0       -0.597052      -2.738786  -0.100749      -0.246630       -0.863700   \n",
            "1       -0.597052       0.365125  -0.100749      -0.832161        1.457428   \n",
            "2        0.354222       0.365125  -0.100749      -0.756259       -0.863700   \n",
            "3       -0.597052      -2.738786  -0.100749      -0.474336        0.379761   \n",
            "4        0.354222      -2.738786  -0.100749      -0.669513       -0.863700   \n",
            "\n",
            "   flight_hour  wants_extra_baggage  wants_preferred_seat  \\\n",
            "0     0.899767            -1.353659             -0.645863   \n",
            "1    -0.206155             0.738738             -0.645863   \n",
            "2    -0.390476             0.738738             -0.645863   \n",
            "3    -0.390476             0.738738             -0.645863   \n",
            "4     0.346806             0.738738              1.548315   \n",
            "\n",
            "   wants_in_flight_meals  flight_duration  ...  flight_day_Fri  \\\n",
            "0               1.186334         1.067510  ...       -0.393532   \n",
            "1              -0.842933        -1.683508  ...       -0.393532   \n",
            "2               1.186334        -0.422625  ...        2.541087   \n",
            "3              -0.842933         1.067510  ...       -0.393532   \n",
            "4               1.186334         0.959627  ...       -0.393532   \n",
            "\n",
            "   flight_day_Mon  flight_day_Sat  flight_day_Sun  flight_day_Thu  \\\n",
            "0       -0.440799       -0.362247       -0.390456       -0.417697   \n",
            "1        2.268610       -0.362247       -0.390456       -0.417697   \n",
            "2       -0.440799       -0.362247       -0.390456       -0.417697   \n",
            "3       -0.440799       -0.362247        2.561108       -0.417697   \n",
            "4       -0.440799        2.760550       -0.390456       -0.417697   \n",
            "\n",
            "   flight_day_Tue  flight_day_Wed  booking_complete  PredictedbookProb  \\\n",
            "0       -0.425316        2.351194                 0           0.165601   \n",
            "1       -0.425316       -0.425316                 0           0.700475   \n",
            "2       -0.425316       -0.425316                 0           0.786394   \n",
            "3       -0.425316       -0.425316                 0           0.728211   \n",
            "4       -0.425316       -0.425316                 1           0.809647   \n",
            "\n",
            "   Predictedbook  \n",
            "0              0  \n",
            "1              1  \n",
            "2              1  \n",
            "3              1  \n",
            "4              1  \n",
            "\n",
            "[5 rows x 914 columns]\n",
            "\n",
            "######### Testing Accuracy Results #########\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.72      0.82      7608\n",
            "           1       0.32      0.75      0.45      1332\n",
            "\n",
            "    accuracy                           0.73      8940\n",
            "   macro avg       0.63      0.74      0.63      8940\n",
            "weighted avg       0.85      0.73      0.76      8940\n",
            "\n",
            "[[5509 2099]\n",
            " [ 335  997]]\n",
            "(0       0\n",
            "1       0\n",
            "2       0\n",
            "3       0\n",
            "4       1\n",
            "       ..\n",
            "8935    0\n",
            "8936    0\n",
            "8937    0\n",
            "8938    0\n",
            "8939    0\n",
            "Name: booking_complete, Length: 8940, dtype: int64, 0       0\n",
            "1       1\n",
            "2       1\n",
            "3       1\n",
            "4       1\n",
            "       ..\n",
            "8935    0\n",
            "8936    0\n",
            "8937    0\n",
            "8938    0\n",
            "8939    1\n",
            "Name: Predictedbook, Length: 8940, dtype: int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = classifier.predict(X_test)\n",
        "print(result)\n",
        "\n",
        "pred_dicts = list(classifier.predict(X_test))\n",
        "probs = pd.Series([float(pred) for pred in pred_dicts])\n",
        "colors_BA = ['#075AAA','#EB2226', '#EFE9E5','#B9CFED']\n",
        "print(probs)\n",
        "probs.plot(kind='hist', bins=20, title='predicted probabilities', color = colors_BA)"
      ],
      "metadata": {
        "id": "NsxrfjSrV4WT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "8590d13e-8566-4c6f-eb78-bfe24259791c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "280/280 [==============================] - 1s 2ms/step\n",
            "[[0.16560106]\n",
            " [0.7004745 ]\n",
            " [0.7863938 ]\n",
            " ...\n",
            " [0.30614147]\n",
            " [0.37063318]\n",
            " [0.8313327 ]]\n",
            "280/280 [==============================] - 0s 1ms/step\n",
            "0       0.165601\n",
            "1       0.700475\n",
            "2       0.786394\n",
            "3       0.728211\n",
            "4       0.809647\n",
            "          ...   \n",
            "8935    0.202170\n",
            "8936    0.324645\n",
            "8937    0.306141\n",
            "8938    0.370633\n",
            "8939    0.831333\n",
            "Length: 8940, dtype: float64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f249bf3f430>"
            ]
          },
          "metadata": {},
          "execution_count": 195
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss(history, label, n):\n",
        "  # Use a log scale on y-axis to show the wide range of values.\n",
        "  plt.semilogy(history.epoch, history.history['loss'],\n",
        "               color='r', label='Train ' + label)\n",
        "  #plt.semilogy(history.epoch, history.history['accuracy'],\n",
        "   #            color='b', label='Val ' + label,\n",
        "    #           linestyle=\"--\")\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "\n",
        "plot_loss(survivalANN_Model, \"Zero Bias\", 0)"
      ],
      "metadata": {
        "id": "dZbIlhn0oteu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "9066187f-644b-4c29-a22a-5d182c0e8c7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}